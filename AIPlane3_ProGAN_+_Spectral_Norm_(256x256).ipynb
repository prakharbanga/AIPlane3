{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakharbanga/AIPlane3/blob/main/AIPlane3_ProGAN_%2B_Spectral_Norm_(256x256).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i2gpG7qiGVE"
      },
      "outputs": [],
      "source": [
        "!pip install -q clu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sjNL3jriNlH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.tree_util import tree_flatten\n",
        "from flax import linen as nn, struct\n",
        "from flax.training import train_state\n",
        "from flax.core import frozen_dict\n",
        "from flax.serialization import (to_state_dict, msgpack_serialize, from_bytes)\n",
        "import optax\n",
        "from clu import metrics\n",
        "import functools\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Any, Optional\n",
        "import glob\n",
        "import os\n",
        "import IPython.display as display\n",
        "import shutil\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoaPK8YNiPTp",
        "outputId": "97136e65-d148-47fa-b5be-0b6149322794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 devices of type Tesla T4\n",
            "Found 1 JAX devices of type Tesla T4.\n",
            "Sat Aug 26 22:13:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    27W /  70W |    389MiB / 15360MiB |      6%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "assert tf.test.gpu_device_name() == \"/device:GPU:0\", \"GPU not found!\"\n",
        "print(f\"Found {jax.device_count()} devices of type {jax.devices()[0].device_kind}\")\n",
        "\n",
        "num_devices = jax.device_count()\n",
        "device_type = jax.devices()[0].device_kind\n",
        "\n",
        "print(f\"Found {num_devices} JAX devices of type {device_type}.\")\n",
        "!nvidia-smi\n",
        "# assert \"TPU\" in device_type, \"Available device is not a TPU, please select TPU from Edit > Notebook settings > Hardware accelerator\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcwAQry9Aar2"
      },
      "outputs": [],
      "source": [
        "def image_to_input(image):\n",
        "  return 2. * image / 255. - 1.\n",
        "\n",
        "def input_to_image(input):\n",
        "  return (input + 1.) * 255. / 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkta07CQyr8M"
      },
      "source": [
        "## Download FGVC Aircraft Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opyHkCV1ye3h"
      },
      "outputs": [],
      "source": [
        "# !wget -nc https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w9C50iDy8oG"
      },
      "outputs": [],
      "source": [
        "# !mkdir /content/fgvc-aircraft-2013b/\n",
        "# if not glob.glob(\"fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images\"):\n",
        "#   !tar -xkf \"/content/fgvc-aircraft-2013b.tar.gz\" -C \"/content/fgvc-aircraft-2013b/\"     #[run this cell to extract tar files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdBuDDyjEmBw"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p fgvc-aircraft-2013b-4/fgvc-aircraft-2013b/data/images\n",
        "\n",
        "# for image_file in glob.glob(\"fgvc-aircraft-2013b/fgvc-aircraft-2013b/data/images/*.jpg\"):\n",
        "#   new_image_file = \"fgvc-aircraft-2013b-4/\" + \"/\".join(image_file.split('/')[1:])\n",
        "#   if glob.glob(new_image_file):\n",
        "#     continue\n",
        "#   with Image.open(image_file) as image:\n",
        "#     image.resize((4, 4)).save(new_image_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnngqiKlgPL1"
      },
      "outputs": [],
      "source": [
        "# !tar -czf fgvc-aircraft-2013b-4.tar.gz fgvc-aircraft-2013b-4/fgvc-aircraft-2013b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH8548wLab9J",
        "outputId": "f99819a0-ba92-4834-c36b-7db1278c38f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘fgvc-aircraft-2013b-256.tar.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘fgvc-aircraft-2013b-128.tar.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘fgvc-aircraft-2013b-64.tar.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘fgvc-aircraft-2013b-32.tar.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘fgvc-aircraft-2013b-16.tar.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘fgvc-aircraft-2013b-8.tar.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘fgvc-aircraft-2013b-4.tar.gz’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://storage.googleapis.com/prak345/fgvc-aircraft-2013b-256.tar.gz\n",
        "!wget -nc https://storage.googleapis.com/prak345/fgvc-aircraft-2013b-128.tar.gz\n",
        "!wget -nc https://storage.googleapis.com/prak345/fgvc-aircraft-2013b-64.tar.gz\n",
        "!wget -nc https://storage.googleapis.com/prak345/fgvc-aircraft-2013b-32.tar.gz\n",
        "!wget -nc https://storage.googleapis.com/prak345/fgvc-aircraft-2013b-16.tar.gz\n",
        "!wget -nc https://storage.googleapis.com/prak345/fgvc-aircraft-2013b-8.tar.gz\n",
        "!wget -nc https://storage.googleapis.com/prak345/fgvc-aircraft-2013b-4.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYWu2tqrflRN"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/fgvc-aircraft-2013b-256/\n",
        "if not glob.glob(\"fgvc-aircraft-2013b-256/fgvc-aircraft-2013b/data/images\"):\n",
        "  !tar -xkf \"/content/fgvc-aircraft-2013b-256.tar.gz\"     #[run this cell to extract tar files]\n",
        "\n",
        "!mkdir -p /content/fgvc-aircraft-2013b-128/\n",
        "if not glob.glob(\"fgvc-aircraft-2013b-128/fgvc-aircraft-2013b/data/images\"):\n",
        "  !tar -xkf \"/content/fgvc-aircraft-2013b-128.tar.gz\"     #[run this cell to extract tar files]\n",
        "\n",
        "!mkdir -p /content/fgvc-aircraft-2013b-64/\n",
        "if not glob.glob(\"fgvc-aircraft-2013b-64/fgvc-aircraft-2013b/data/images\"):\n",
        "  !tar -xkf \"/content/fgvc-aircraft-2013b-64.tar.gz\"     #[run this cell to extract tar files]\n",
        "\n",
        "!mkdir -p /content/fgvc-aircraft-2013b-32/\n",
        "if not glob.glob(\"fgvc-aircraft-2013b-32/fgvc-aircraft-2013b/data/images\"):\n",
        "  !tar -xkf \"/content/fgvc-aircraft-2013b-32.tar.gz\"     #[run this cell to extract tar files]\n",
        "\n",
        "!mkdir -p /content/fgvc-aircraft-2013b-16/\n",
        "if not glob.glob(\"fgvc-aircraft-2013b-16/fgvc-aircraft-2013b/data/images\"):\n",
        "  !tar -xkf \"/content/fgvc-aircraft-2013b-16.tar.gz\"     #[run this cell to extract tar files]\n",
        "\n",
        "!mkdir -p /content/fgvc-aircraft-2013b-8/\n",
        "if not glob.glob(\"fgvc-aircraft-2013b-8/fgvc-aircraft-2013b/data/images\"):\n",
        "  !tar -xkf \"/content/fgvc-aircraft-2013b-8.tar.gz\"     #[run this cell to extract tar files]\n",
        "\n",
        "!mkdir -p /content/fgvc-aircraft-2013b-4/\n",
        "if not glob.glob(\"fgvc-aircraft-2013b-4/fgvc-aircraft-2013b/data/images\"):\n",
        "  !tar -xkf \"/content/fgvc-aircraft-2013b-4.tar.gz\"     #[run this cell to extract tar files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHfsQCUiz8Bz"
      },
      "outputs": [],
      "source": [
        "def concat(dss):\n",
        "  return functools.reduce(lambda x, y: x.concatenate(y), dss)\n",
        "\n",
        "def split_dataset(dataset, *args):\n",
        "  cumsplits = np.cumsum(args).tolist()\n",
        "  total = cumsplits[-1]\n",
        "  return [concat([dataset.shard(total, split) for split in range(start, end)]) for (start, end) in zip([0] + cumsplits, cumsplits)]\n",
        "\n",
        "def get_datasets(num_epochs, batch_sizes):\n",
        "  sample_fn = lambda sample: image_to_input(tf.cast(sample, tf.float32))\n",
        "  dss = []\n",
        "  first_fn = (lambda x, y: x)\n",
        "  for (resindex, resolution) in enumerate([4, 8, 16, 32, 64, 128, 256]):\n",
        "    (train, test) = split_dataset(tf.keras.utils.image_dataset_from_directory(f\"/content/fgvc-aircraft-2013b-{resolution}\", image_size=(resolution, resolution), batch_size=batch_sizes[resindex]), 90, 10)\n",
        "    # 256x256 dataset doesn't fit in memory/cache and crashes the runtime.\n",
        "    dss.append(((train.map(first_fn).map(sample_fn).cache() if resolution <= 128 else train.map(first_fn).map(sample_fn).cache(f\"cache_res{resolution}_{int(time.time())}\")).repeat(num_epochs).prefetch(tf.data.AUTOTUNE),\n",
        "               test.map(first_fn).map(sample_fn).cache().prefetch(tf.data.AUTOTUNE)))\n",
        "  return dss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nro0Xh_q0rEC",
        "outputId": "48e2174a-04b1-44ce-d2a6-6b245f922865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 1 classes.\n",
            "Found 10000 files belonging to 1 classes.\n",
            "Found 10000 files belonging to 1 classes.\n",
            "Found 10000 files belonging to 1 classes.\n",
            "Found 10000 files belonging to 1 classes.\n",
            "Found 10000 files belonging to 1 classes.\n",
            "Found 10000 files belonging to 1 classes.\n",
            "Test dataset size: 640\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10_000_000\n",
        "batch_sizes = [64, 64, 64, 64, 64, 64, 64]\n",
        "if 'datasets' not in globals():\n",
        "  datasets = get_datasets(num_epochs, batch_sizes)\n",
        "assert len(batch_sizes) == len(datasets)\n",
        "for (idx, test_ds) in enumerate(np.array(datasets)[:,1]):\n",
        "  for batch in test_ds.as_numpy_iterator():\n",
        "    assert batch.shape[1:] == (4 * 2 ** idx, 4 * 2 ** idx, 3), f\"Batch shape is {batch.shape}\"\n",
        "print(f\"Test dataset size: {sum([batch.shape[0] for batch in datasets[3][1].as_numpy_iterator()])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx0AQh7QzXky"
      },
      "outputs": [],
      "source": [
        "REAL_LABEL = 0\n",
        "FAKE_LABEL = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TbWtGIEkBMfd",
        "outputId": "95373f71-46ad-49dd-b98c-b87ac5c6f4f4"
      },
      "outputs": [],
      "source": [
        "def gridify(grid):\n",
        "  num = grid.shape[0]\n",
        "  height = grid[0].shape[0]\n",
        "  width = grid[0].shape[1]\n",
        "  col = math.ceil(math.sqrt(num))\n",
        "  row = col-1 if col*(col-1) >= num else col\n",
        "  padded = np.concatenate([grid, np.zeros([row*col-num]+list(grid[0].shape))], axis=0)\n",
        "  return np.transpose(padded.reshape((row, col, height, width, 3)), axes=(0, 2, 1, 3, 4)).reshape(row*height, col*width, 3)\n",
        "\n",
        "for dataset in datasets[::-1]:\n",
        "  elems = list(dataset[0].take(1).get_single_element())\n",
        "  display.display(Image.fromarray(input_to_image(gridify(np.array([elem.numpy() for elem in elems]))).astype(np.uint8)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqJJ_0dasVS8"
      },
      "source": [
        "## Spectral Norm Module (borrowed from Haiku)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekhzh1OYsUju"
      },
      "outputs": [],
      "source": [
        "# Original Source: https://github.com/deepmind/dm-haiku/blob/main/haiku/_src/spectral_norm.py\n",
        "\n",
        "def _l2_normalize(x, axis=None, eps=1e-12):\n",
        "  \"\"\"Normalizes along dimension `axis` using an L2 norm.\n",
        "\n",
        "  This specialized function exists for numerical stability reasons.\n",
        "\n",
        "  Args:\n",
        "    x: An input ndarray.\n",
        "    axis: Dimension along which to normalize, e.g. `1` to separately normalize\n",
        "      vectors in a batch. Passing `None` views `t` as a flattened vector when\n",
        "      calculating the norm (equivalent to Frobenius norm).\n",
        "    eps: Epsilon to avoid dividing by zero.\n",
        "\n",
        "  Returns:\n",
        "    An array of the same shape as 'x' L2-normalized along 'axis'.\n",
        "  \"\"\"\n",
        "  return x * jax.lax.rsqrt((x * x).sum(axis=axis, keepdims=True) + eps)\n",
        "\n",
        "\n",
        "class SpectralNorm(nn.Module):\n",
        "  \"\"\"Normalizes an input by its first singular value.\n",
        "\n",
        "  This module uses power iteration to calculate this value based on the\n",
        "  input and an internal hidden state.\n",
        "\n",
        "  update_stats: A boolean defaulting to True. Regardless of this arg, this\n",
        "    function will return the normalized input. When\n",
        "    `update_stats` is True, the internal state of this object will also be\n",
        "    updated to reflect the input value. When `update_stats` is False the\n",
        "    internal stats will remain unchanged.\n",
        "  error_on_non_matrix: Spectral normalization is only defined on matrices.\n",
        "    By default, this module will return scalars unchanged and flatten\n",
        "    higher-order tensors in their leading dimensions. Setting this flag to\n",
        "    True will instead throw errors in those cases.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  wrapped: nn.Module\n",
        "  update_stats: bool = True\n",
        "  error_on_non_matrix: bool = False\n",
        "  eps: float = 1e-4\n",
        "  n_steps: int = 1\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(\n",
        "      self,\n",
        "      value: jax.Array\n",
        "  ) -> jax.Array:\n",
        "    \"\"\"Wraps a layer with Spectral Normalization.\n",
        "\n",
        "    Args:\n",
        "      value: The value (Array-like) for which you would like to perform an\n",
        "        spectral normalization after the wrapped layer.\n",
        "    Returns:\n",
        "      The output of the wrapped layer normalized by it's first singular value.\n",
        "    Raises:\n",
        "      ValueError: If `error_on_non_matrix` is True and `value` has ndims > 2.\n",
        "    \"\"\"\n",
        "\n",
        "    u0 = self.variable(\n",
        "        'spectral_norm_stats', 'u0', lambda s: jnp.ones(s, jnp.float32), (1, self.wrapped.features)\n",
        "    )\n",
        "\n",
        "    if 'params' not in self.wrapped.variables or 'kernel' not in self.wrapped.variables['params']:\n",
        "      return self.wrapped(value)\n",
        "\n",
        "    kernel = self.wrapped.variables['params']['kernel']\n",
        "\n",
        "    # Handle scalars.\n",
        "    if kernel.ndim <= 1:\n",
        "      raise ValueError(\"Spectral normalization is not well defined for \"\n",
        "                       \"scalar or vector inputs.\")\n",
        "    # Handle higher-order tensors.\n",
        "    elif kernel.ndim > 2:\n",
        "      if self.error_on_non_matrix:\n",
        "        raise ValueError(\n",
        "            f\"Input is {kernel.ndim}D but error_on_non_matrix is True\")\n",
        "      else:\n",
        "        kernel = jnp.reshape(kernel, [-1, kernel.shape[-1]])\n",
        "\n",
        "    u0_val = u0.value\n",
        "\n",
        "    # Power iteration for the weight's singular value.\n",
        "    for _ in range(self.n_steps):\n",
        "      v0_val = _l2_normalize(jnp.matmul(u0_val, kernel.transpose([1, 0])), eps=self.eps)\n",
        "      u0_val = _l2_normalize(jnp.matmul(v0_val, kernel), eps=self.eps)\n",
        "\n",
        "    u0_val = jax.lax.stop_gradient(u0_val)\n",
        "    v0_val = jax.lax.stop_gradient(v0_val)\n",
        "\n",
        "    sigma = jnp.matmul(jnp.matmul(v0_val, kernel), jnp.transpose(u0_val))[0, 0]\n",
        "\n",
        "    if self.update_stats:\n",
        "      u0.value = u0_val\n",
        "\n",
        "    return self.wrapped(value) / (sigma + 1e-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JGtpWLQJbmt"
      },
      "source": [
        "## End of Spectral Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmW4cY2Yla42"
      },
      "source": [
        "## Local Response Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qov3It1lg-K"
      },
      "outputs": [],
      "source": [
        "class LocalResponseNorm(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(\n",
        "      self,\n",
        "      value: jax.Array\n",
        "  ) -> jax.Array:\n",
        "    return value / jnp.repeat(jnp.expand_dims((1e-8 + (value**2).mean(axis=-1))**0.5, axis=-1), repeats=value.shape[-1], axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJlSiYyLlbEK"
      },
      "source": [
        "## End of Local Response Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko0OaLPG12wQ"
      },
      "outputs": [],
      "source": [
        "EPSILON = 1e-8\n",
        "MAX_DISC_FEATURES = 128\n",
        "MAX_GEN_FEATURES = 512\n",
        "LATENT_DIM = 512\n",
        "MAX_LAYERS = 7 # 256x256\n",
        "\n",
        "def get_disc_layers(layer, name_suffix=\"\"):\n",
        "  resolution = int(4 * 2 ** layer)\n",
        "  features = min(int(32 * 2 ** (MAX_LAYERS - 1 - layer)), MAX_DISC_FEATURES)\n",
        "  layers = []\n",
        "  layers.append(lambda x, training: jax.image.resize(x, shape=(x.shape[0], resolution, resolution, x.shape[3]), method=\"linear\"))\n",
        "  layers.append(lambda x, training: SpectralNorm(nn.Conv(features=features, kernel_size=(3, 3), name=f\"Conv_{resolution}_{features}{name_suffix}\"), update_stats=training, name=f\"SN_{resolution}_{features}{name_suffix}\")(x))\n",
        "  layers.append(lambda x, training: nn.leaky_relu(x, negative_slope=0.2))\n",
        "  return layers\n",
        "\n",
        "def get_final_disc_layers():\n",
        "  features = min(int(32 * 2 ** (MAX_LAYERS - 1)), MAX_DISC_FEATURES)\n",
        "  layers = []\n",
        "  layers.append(lambda x, training: SpectralNorm(nn.Conv(features=features, kernel_size=(4, 4), padding=\"VALID\", name=f\"Conv_1_{features}\"), update_stats=training, name=f\"SN_1_{features}\")(x))\n",
        "  layers.append(lambda x, training: x.reshape((x.shape[0], -1)))\n",
        "  layers.append(lambda x, training: SpectralNorm(nn.Dense(features=1, name=\"Dense\"), update_stats=training, name=\"SN_Dense\")(x))\n",
        "  layers.append(lambda x, training: nn.tanh(x))\n",
        "  return layers\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  num_layers: int = None\n",
        "\n",
        "  def setup(self):\n",
        "    # 256x256x3 => 256x256x32 => 128x128x64 => 64x64x128 => 32x32x128 => 16x16x128 => 8x8x128 => 4x4x128 => 1x1x128 => 1x1x1\n",
        "    layers = []\n",
        "    for layer in range(self.num_layers-1, -1, -1):\n",
        "      layers.extend(get_disc_layers(layer))\n",
        "    layers.extend(get_final_disc_layers())\n",
        "    self.layers = layers\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, training=True):\n",
        "    result = x\n",
        "    for layer in self.layers:\n",
        "      result = layer(result, training)\n",
        "    return result\n",
        "\n",
        "class TransitionDiscriminator(nn.Module):\n",
        "  num_layers: int = None\n",
        "\n",
        "  def setup(self):\n",
        "    large_layers = []\n",
        "    large_layers.extend(get_disc_layers(self.num_layers-1))\n",
        "    large_layers.extend(get_disc_layers(self.num_layers-2, \"_large\"))\n",
        "\n",
        "    small_layers = []\n",
        "    small_layers.extend(get_disc_layers(self.num_layers-2))\n",
        "\n",
        "    combined_layers = []\n",
        "    for layer in range(self.num_layers-3, -1, -1):\n",
        "      combined_layers.extend(get_disc_layers(layer))\n",
        "    combined_layers.extend(get_final_disc_layers())\n",
        "\n",
        "    self.large_layers = large_layers\n",
        "    self.small_layers = small_layers\n",
        "    self.combined_layers = combined_layers\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, large, small, alpha, training=True):\n",
        "    large_result = large\n",
        "    for layer in self.large_layers:\n",
        "      large_result = layer(large_result, training)\n",
        "\n",
        "    small_result = small\n",
        "    for layer in self.small_layers:\n",
        "      small_result = layer(small_result, training)\n",
        "\n",
        "    result = alpha * small_result + (1-alpha) * large_result\n",
        "    for layer in self.combined_layers:\n",
        "      result = layer(result, training)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_gen_layers(layer):\n",
        "  resolution = int(4 * 2 ** layer)\n",
        "  features = min(int(32 * 2 ** (MAX_LAYERS - 1 - layer)), MAX_GEN_FEATURES)\n",
        "  layers = []\n",
        "  layers.append(lambda x: jax.image.resize(x, shape=(x.shape[0], resolution, resolution, x.shape[3]), method=\"linear\"))\n",
        "  layers.append(lambda x: nn.ConvTranspose(features=features, kernel_size=(3, 3), name=f\"ConvTranspose_{resolution}_{features}\")(x))\n",
        "  layers.append(lambda x: nn.relu(x))\n",
        "  return layers\n",
        "\n",
        "def get_initial_gen_layers(num_layers):\n",
        "  layers = []\n",
        "  layers.append(lambda x: x.reshape(x.shape[0], 1, 1, -1))\n",
        "  return layers\n",
        "\n",
        "def get_final_gen_layers(num_layers):\n",
        "  resolution = int(4 * 2 ** (num_layers - 1))\n",
        "  layers = []\n",
        "  layers.append(lambda x: nn.ConvTranspose(features=3, kernel_size=(3, 3), name=f\"ConvTranspose_{resolution}_3\")(x))\n",
        "  return layers\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  num_layers: int = None\n",
        "\n",
        "  def setup(self):\n",
        "    # 512 => 1x1x512 => 4x4x512 => 8x8x512 => 16x16x512 => 32x32x256 => 64x64x128 => 128x128x64 => 256x256x32 => 256x256x3\n",
        "    layers = []\n",
        "    layers.extend(get_initial_gen_layers(self.num_layers))\n",
        "    for layer in range(self.num_layers):\n",
        "      layers.extend(get_gen_layers(layer))\n",
        "    layers.extend(get_final_gen_layers(self.num_layers))\n",
        "    self.layers = layers\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    result = x\n",
        "    for layer in self.layers:\n",
        "      result = layer(result)\n",
        "    return result\n",
        "\n",
        "class TransitionGenerator(nn.Module):\n",
        "  num_layers: int = None\n",
        "\n",
        "  def setup(self):\n",
        "    combined_layers = []\n",
        "    combined_layers.extend(get_initial_gen_layers(self.num_layers))\n",
        "    for layer in range(self.num_layers-1):\n",
        "      combined_layers.extend(get_gen_layers(layer))\n",
        "    small_layers = []\n",
        "    small_layers.extend(get_final_gen_layers(self.num_layers-1))\n",
        "    large_layers = []\n",
        "    large_layers.extend(get_gen_layers(self.num_layers-1))\n",
        "    large_layers.extend(get_final_gen_layers(self.num_layers))\n",
        "\n",
        "    self.large_layers = large_layers\n",
        "    self.small_layers = small_layers\n",
        "    self.combined_layers = combined_layers\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    result = x\n",
        "    for layer in self.combined_layers:\n",
        "      result = layer(result)\n",
        "    small_result = result\n",
        "    for layer in self.small_layers:\n",
        "      small_result = layer(small_result)\n",
        "    large_result = result\n",
        "    for layer in self.large_layers:\n",
        "      large_result = layer(large_result)\n",
        "    return (large_result, small_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nygKjnpu1yql",
        "outputId": "616be0bc-00c1-447e-cdb4-0d90ea5a7a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[3m                                                 Discriminator Summary                                                  \u001b[0m\n",
            "┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mspectral_norm_stats\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│             │ Discriminator │ \u001b[2mfloat32\u001b[0m[10,256,256… │ \u001b[2mfloat32\u001b[0m[10,1]        │                     │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_256_32   │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,256,256… │ \u001b[2mfloat32\u001b[0m[10,256,256,… │                     │ u0: \u001b[2mfloat32\u001b[0m[1,32]   │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m32 \u001b[0m\u001b[1;2m(128 B)\u001b[0m          │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Conv_256_32 │ Conv          │ \u001b[2mfloat32\u001b[0m[10,256,256… │ \u001b[2mfloat32\u001b[0m[10,256,256,… │ bias: \u001b[2mfloat32\u001b[0m[32]   │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[3,3,3,32]   │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m896 \u001b[0m\u001b[1;2m(3.6 KB)\u001b[0m        │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_128_64   │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,128,128… │ \u001b[2mfloat32\u001b[0m[10,128,128,… │                     │ u0: \u001b[2mfloat32\u001b[0m[1,64]   │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m          │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Conv_128_64 │ Conv          │ \u001b[2mfloat32\u001b[0m[10,128,128… │ \u001b[2mfloat32\u001b[0m[10,128,128,… │ bias: \u001b[2mfloat32\u001b[0m[64]   │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[3,3,32,64]  │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m18,496 \u001b[0m\u001b[1;2m(74.0 KB)\u001b[0m    │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_64_128   │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,64,64,6… │ \u001b[2mfloat32\u001b[0m[10,64,64,12… │                     │ u0: \u001b[2mfloat32\u001b[0m[1,128]  │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m         │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Conv_64_128 │ Conv          │ \u001b[2mfloat32\u001b[0m[10,64,64,6… │ \u001b[2mfloat32\u001b[0m[10,64,64,12… │ bias: \u001b[2mfloat32\u001b[0m[128]  │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[3,3,64,128] │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m73,856 \u001b[0m\u001b[1;2m(295.4 KB)\u001b[0m   │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_32_128   │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,32,32,1… │ \u001b[2mfloat32\u001b[0m[10,32,32,12… │                     │ u0: \u001b[2mfloat32\u001b[0m[1,128]  │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m         │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Conv_32_128 │ Conv          │ \u001b[2mfloat32\u001b[0m[10,32,32,1… │ \u001b[2mfloat32\u001b[0m[10,32,32,12… │ bias: \u001b[2mfloat32\u001b[0m[128]  │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[3,3,128,12… │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 KB)\u001b[0m  │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_16_128   │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,16,16,1… │ \u001b[2mfloat32\u001b[0m[10,16,16,12… │                     │ u0: \u001b[2mfloat32\u001b[0m[1,128]  │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m         │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Conv_16_128 │ Conv          │ \u001b[2mfloat32\u001b[0m[10,16,16,1… │ \u001b[2mfloat32\u001b[0m[10,16,16,12… │ bias: \u001b[2mfloat32\u001b[0m[128]  │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[3,3,128,12… │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 KB)\u001b[0m  │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_8_128    │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,8,8,128] │ \u001b[2mfloat32\u001b[0m[10,8,8,128]  │                     │ u0: \u001b[2mfloat32\u001b[0m[1,128]  │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m         │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Conv_8_128  │ Conv          │ \u001b[2mfloat32\u001b[0m[10,8,8,128] │ \u001b[2mfloat32\u001b[0m[10,8,8,128]  │ bias: \u001b[2mfloat32\u001b[0m[128]  │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[3,3,128,12… │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 KB)\u001b[0m  │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_4_128    │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,4,4,128] │ \u001b[2mfloat32\u001b[0m[10,4,4,128]  │                     │ u0: \u001b[2mfloat32\u001b[0m[1,128]  │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m         │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Conv_4_128  │ Conv          │ \u001b[2mfloat32\u001b[0m[10,4,4,128] │ \u001b[2mfloat32\u001b[0m[10,4,4,128]  │ bias: \u001b[2mfloat32\u001b[0m[128]  │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[3,3,128,12… │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 KB)\u001b[0m  │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_1_128    │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,4,4,128] │ \u001b[2mfloat32\u001b[0m[10,1,1,128]  │                     │ u0: \u001b[2mfloat32\u001b[0m[1,128]  │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m         │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Conv_1_128  │ Conv          │ \u001b[2mfloat32\u001b[0m[10,4,4,128] │ \u001b[2mfloat32\u001b[0m[10,1,1,128]  │ bias: \u001b[2mfloat32\u001b[0m[128]  │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[4,4,128,12… │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m262,272 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m    │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ SN_Dense    │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,128]     │ \u001b[2mfloat32\u001b[0m[10,1]        │                     │ u0: \u001b[2mfloat32\u001b[0m[1,1]    │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │                     │ \u001b[1m1 \u001b[0m\u001b[1;2m(4 B)\u001b[0m             │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│ Dense       │ Dense         │ \u001b[2mfloat32\u001b[0m[10,128]     │ \u001b[2mfloat32\u001b[0m[10,1]        │ bias: \u001b[2mfloat32\u001b[0m[1]    │                     │\n",
            "│             │               │                     │                      │ kernel:             │                     │\n",
            "│             │               │                     │                      │ \u001b[2mfloat32\u001b[0m[128,1]      │                     │\n",
            "│             │               │                     │                      │                     │                     │\n",
            "│             │               │                     │                      │ \u001b[1m129 \u001b[0m\u001b[1;2m(516 B)\u001b[0m         │                     │\n",
            "├─────────────┼───────────────┼─────────────────────┼──────────────────────┼─────────────────────┼─────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m945,985 \u001b[0m\u001b[1;2m(3.8 MB)\u001b[0m\u001b[1m   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m865 \u001b[0m\u001b[1;2m(3.5 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
            "└─────────────┴───────────────┴─────────────────────┴──────────────────────┴─────────────────────┴─────────────────────┘\n",
            "\u001b[1m                                                                                                                        \u001b[0m\n",
            "\u001b[1m                                           Total Parameters: 946,850 \u001b[0m\u001b[1;2m(3.8 MB)\u001b[0m\u001b[1m                                           \u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[3m                                                   Generator Summary                                                    \u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                    \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│                      │ Generator     │ \u001b[2mfloat32\u001b[0m[10,512]         │ \u001b[2mfloat32\u001b[0m[10,256,256,3]  │                            │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│ ConvTranspose_4_512  │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,4,4,512]     │ \u001b[2mfloat32\u001b[0m[10,4,4,512]    │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
            "│                      │               │                         │                        │ kernel:                    │\n",
            "│                      │               │                         │                        │ \u001b[2mfloat32\u001b[0m[3,3,512,512]       │\n",
            "│                      │               │                         │                        │                            │\n",
            "│                      │               │                         │                        │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m         │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│ ConvTranspose_8_512  │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,8,8,512]     │ \u001b[2mfloat32\u001b[0m[10,8,8,512]    │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
            "│                      │               │                         │                        │ kernel:                    │\n",
            "│                      │               │                         │                        │ \u001b[2mfloat32\u001b[0m[3,3,512,512]       │\n",
            "│                      │               │                         │                        │                            │\n",
            "│                      │               │                         │                        │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m         │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│ ConvTranspose_16_512 │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,16,16,512]   │ \u001b[2mfloat32\u001b[0m[10,16,16,512]  │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
            "│                      │               │                         │                        │ kernel:                    │\n",
            "│                      │               │                         │                        │ \u001b[2mfloat32\u001b[0m[3,3,512,512]       │\n",
            "│                      │               │                         │                        │                            │\n",
            "│                      │               │                         │                        │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m         │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│ ConvTranspose_32_256 │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,32,32,512]   │ \u001b[2mfloat32\u001b[0m[10,32,32,256]  │ bias: \u001b[2mfloat32\u001b[0m[256]         │\n",
            "│                      │               │                         │                        │ kernel:                    │\n",
            "│                      │               │                         │                        │ \u001b[2mfloat32\u001b[0m[3,3,512,256]       │\n",
            "│                      │               │                         │                        │                            │\n",
            "│                      │               │                         │                        │ \u001b[1m1,179,904 \u001b[0m\u001b[1;2m(4.7 MB)\u001b[0m         │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│ ConvTranspose_64_128 │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,64,64,256]   │ \u001b[2mfloat32\u001b[0m[10,64,64,128]  │ bias: \u001b[2mfloat32\u001b[0m[128]         │\n",
            "│                      │               │                         │                        │ kernel:                    │\n",
            "│                      │               │                         │                        │ \u001b[2mfloat32\u001b[0m[3,3,256,128]       │\n",
            "│                      │               │                         │                        │                            │\n",
            "│                      │               │                         │                        │ \u001b[1m295,040 \u001b[0m\u001b[1;2m(1.2 MB)\u001b[0m           │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│ ConvTranspose_128_64 │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,128,128,128] │ \u001b[2mfloat32\u001b[0m[10,128,128,64] │ bias: \u001b[2mfloat32\u001b[0m[64]          │\n",
            "│                      │               │                         │                        │ kernel:                    │\n",
            "│                      │               │                         │                        │ \u001b[2mfloat32\u001b[0m[3,3,128,64]        │\n",
            "│                      │               │                         │                        │                            │\n",
            "│                      │               │                         │                        │ \u001b[1m73,792 \u001b[0m\u001b[1;2m(295.2 KB)\u001b[0m          │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│ ConvTranspose_256_32 │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,256,256,64]  │ \u001b[2mfloat32\u001b[0m[10,256,256,32] │ bias: \u001b[2mfloat32\u001b[0m[32]          │\n",
            "│                      │               │                         │                        │ kernel: \u001b[2mfloat32\u001b[0m[3,3,64,32] │\n",
            "│                      │               │                         │                        │                            │\n",
            "│                      │               │                         │                        │ \u001b[1m18,464 \u001b[0m\u001b[1;2m(73.9 KB)\u001b[0m           │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│ ConvTranspose_256_3  │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,256,256,32]  │ \u001b[2mfloat32\u001b[0m[10,256,256,3]  │ bias: \u001b[2mfloat32\u001b[0m[3]           │\n",
            "│                      │               │                         │                        │ kernel: \u001b[2mfloat32\u001b[0m[3,3,32,3]  │\n",
            "│                      │               │                         │                        │                            │\n",
            "│                      │               │                         │                        │ \u001b[1m867 \u001b[0m\u001b[1;2m(3.5 KB)\u001b[0m               │\n",
            "├──────────────────────┼───────────────┼─────────────────────────┼────────────────────────┼────────────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m                    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m8,647,491 \u001b[0m\u001b[1;2m(34.6 MB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
            "└──────────────────────┴───────────────┴─────────────────────────┴────────────────────────┴────────────────────────────┘\n",
            "\u001b[1m                                                                                                                        \u001b[0m\n",
            "\u001b[1m                                         Total Parameters: 8,647,491 \u001b[0m\u001b[1;2m(34.6 MB)\u001b[0m\u001b[1m                                          \u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[3m                                            TransitionDiscriminator Summary                                             \u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mspectral_norm_s…\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│                   │ TransitionDiscri… │ -                 │ \u001b[2mfloat32\u001b[0m[10,1]     │                   │                  │\n",
            "│                   │                   │ \u001b[2mfloat32\u001b[0m[10,256,2… │                   │                   │                  │\n",
            "│                   │                   │ -                 │                   │                   │                  │\n",
            "│                   │                   │ \u001b[2mfloat32\u001b[0m[10,128,1… │                   │                   │                  │\n",
            "│                   │                   │ - 0.5             │                   │                   │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_256_32         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,256,2… │ \u001b[2mfloat32\u001b[0m[10,256,2… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,32]    │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m32 \u001b[0m\u001b[1;2m(128 B)\u001b[0m       │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_256_32       │ Conv              │ \u001b[2mfloat32\u001b[0m[10,256,2… │ \u001b[2mfloat32\u001b[0m[10,256,2… │ bias: \u001b[2mfloat32\u001b[0m[32] │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,3,32] │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m896 \u001b[0m\u001b[1;2m(3.6 KB)\u001b[0m      │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_128_64_large   │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,128,1… │ \u001b[2mfloat32\u001b[0m[10,128,1… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,64]    │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m       │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_128_64_large │ Conv              │ \u001b[2mfloat32\u001b[0m[10,128,1… │ \u001b[2mfloat32\u001b[0m[10,128,1… │ bias: \u001b[2mfloat32\u001b[0m[64] │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,32,6… │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m18,496 \u001b[0m\u001b[1;2m(74.0 KB)\u001b[0m  │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_128_64         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,128,1… │ \u001b[2mfloat32\u001b[0m[10,128,1… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,64]    │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m64 \u001b[0m\u001b[1;2m(256 B)\u001b[0m       │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_128_64       │ Conv              │ \u001b[2mfloat32\u001b[0m[10,128,1… │ \u001b[2mfloat32\u001b[0m[10,128,1… │ bias: \u001b[2mfloat32\u001b[0m[64] │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,3,64] │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m1,792 \u001b[0m\u001b[1;2m(7.2 KB)\u001b[0m    │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_64_128         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,64,64… │ \u001b[2mfloat32\u001b[0m[10,64,64… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]   │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m      │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_64_128       │ Conv              │ \u001b[2mfloat32\u001b[0m[10,64,64… │ \u001b[2mfloat32\u001b[0m[10,64,64… │ bias:             │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,64,1… │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m73,856 \u001b[0m\u001b[1;2m(295.4 KB)\u001b[0m │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_32_128         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,32,32… │ \u001b[2mfloat32\u001b[0m[10,32,32… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]   │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m      │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_32_128       │ Conv              │ \u001b[2mfloat32\u001b[0m[10,32,32… │ \u001b[2mfloat32\u001b[0m[10,32,32… │ bias:             │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,128,… │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 \u001b[0m   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1;2mKB)\u001b[0m               │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_16_128         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,16,16… │ \u001b[2mfloat32\u001b[0m[10,16,16… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]   │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m      │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_16_128       │ Conv              │ \u001b[2mfloat32\u001b[0m[10,16,16… │ \u001b[2mfloat32\u001b[0m[10,16,16… │ bias:             │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,128,… │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 \u001b[0m   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1;2mKB)\u001b[0m               │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_8_128          │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,8,8,1… │ \u001b[2mfloat32\u001b[0m[10,8,8,1… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]   │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m      │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_8_128        │ Conv              │ \u001b[2mfloat32\u001b[0m[10,8,8,1… │ \u001b[2mfloat32\u001b[0m[10,8,8,1… │ bias:             │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,128,… │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 \u001b[0m   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1;2mKB)\u001b[0m               │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_4_128          │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]   │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m      │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_4_128        │ Conv              │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ bias:             │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,128,… │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 \u001b[0m   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1;2mKB)\u001b[0m               │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_1_128          │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ \u001b[2mfloat32\u001b[0m[10,1,1,1… │                   │ u0:              │\n",
            "│                   │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]   │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m      │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Conv_1_128        │ Conv              │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ \u001b[2mfloat32\u001b[0m[10,1,1,1… │ bias:             │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[4,4,128,… │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m262,272 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m  │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ SN_Dense          │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,128]   │ \u001b[2mfloat32\u001b[0m[10,1]     │                   │ u0: \u001b[2mfloat32\u001b[0m[1,1] │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │                   │ \u001b[1m1 \u001b[0m\u001b[1;2m(4 B)\u001b[0m          │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│ Dense             │ Dense             │ \u001b[2mfloat32\u001b[0m[10,128]   │ \u001b[2mfloat32\u001b[0m[10,1]     │ bias: \u001b[2mfloat32\u001b[0m[1]  │                  │\n",
            "│                   │                   │                   │                   │ kernel:           │                  │\n",
            "│                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128,1]    │                  │\n",
            "│                   │                   │                   │                   │                   │                  │\n",
            "│                   │                   │                   │                   │ \u001b[1m129 \u001b[0m\u001b[1;2m(516 B)\u001b[0m       │                  │\n",
            "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m947,777 \u001b[0m\u001b[1;2m(3.8 MB)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m929 \u001b[0m\u001b[1;2m(3.7 KB)\u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\n",
            "└───────────────────┴───────────────────┴───────────────────┴───────────────────┴───────────────────┴──────────────────┘\n",
            "\u001b[1m                                                                                                                        \u001b[0m\n",
            "\u001b[1m                                           Total Parameters: 948,706 \u001b[0m\u001b[1;2m(3.8 MB)\u001b[0m\u001b[1m                                           \u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[3m                                              TransitionGenerator Summary                                               \u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│                      │ TransitionGenerator │ \u001b[2mfloat32\u001b[0m[10,512]        │ -                     │                        │\n",
            "│                      │                     │                        │ \u001b[2mfloat32\u001b[0m[10,256,256,3] │                        │\n",
            "│                      │                     │                        │ -                     │                        │\n",
            "│                      │                     │                        │ \u001b[2mfloat32\u001b[0m[10,128,128,3] │                        │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_4_512  │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,4,4,512]    │ \u001b[2mfloat32\u001b[0m[10,4,4,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]     │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,512,512]   │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m     │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_8_512  │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,8,8,512]    │ \u001b[2mfloat32\u001b[0m[10,8,8,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]     │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,512,512]   │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m     │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_16_512 │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,16,16,512]  │ \u001b[2mfloat32\u001b[0m[10,16,16,512] │ bias: \u001b[2mfloat32\u001b[0m[512]     │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,512,512]   │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m     │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_32_256 │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,32,32,512]  │ \u001b[2mfloat32\u001b[0m[10,32,32,256] │ bias: \u001b[2mfloat32\u001b[0m[256]     │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,512,256]   │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m1,179,904 \u001b[0m\u001b[1;2m(4.7 MB)\u001b[0m     │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_64_128 │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,64,64,256]  │ \u001b[2mfloat32\u001b[0m[10,64,64,128] │ bias: \u001b[2mfloat32\u001b[0m[128]     │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,256,128]   │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m295,040 \u001b[0m\u001b[1;2m(1.2 MB)\u001b[0m       │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_128_64 │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,128,128,12… │ \u001b[2mfloat32\u001b[0m[10,128,128,6… │ bias: \u001b[2mfloat32\u001b[0m[64]      │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,128,64]    │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m73,792 \u001b[0m\u001b[1;2m(295.2 KB)\u001b[0m      │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_128_3  │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,128,128,64] │ \u001b[2mfloat32\u001b[0m[10,128,128,3] │ bias: \u001b[2mfloat32\u001b[0m[3]       │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,64,3]      │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m1,731 \u001b[0m\u001b[1;2m(6.9 KB)\u001b[0m         │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_256_32 │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,256,256,64] │ \u001b[2mfloat32\u001b[0m[10,256,256,3… │ bias: \u001b[2mfloat32\u001b[0m[32]      │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,64,32]     │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m18,464 \u001b[0m\u001b[1;2m(73.9 KB)\u001b[0m       │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│ ConvTranspose_256_3  │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,256,256,32] │ \u001b[2mfloat32\u001b[0m[10,256,256,3] │ bias: \u001b[2mfloat32\u001b[0m[3]       │\n",
            "│                      │                     │                        │                       │ kernel:                │\n",
            "│                      │                     │                        │                       │ \u001b[2mfloat32\u001b[0m[3,3,32,3]      │\n",
            "│                      │                     │                        │                       │                        │\n",
            "│                      │                     │                        │                       │ \u001b[1m867 \u001b[0m\u001b[1;2m(3.5 KB)\u001b[0m           │\n",
            "├──────────────────────┼─────────────────────┼────────────────────────┼───────────────────────┼────────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m                    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m8,649,222 \u001b[0m\u001b[1;2m(34.6 MB)\u001b[0m\u001b[1m   \u001b[0m\u001b[1m \u001b[0m│\n",
            "└──────────────────────┴─────────────────────┴────────────────────────┴───────────────────────┴────────────────────────┘\n",
            "\u001b[1m                                                                                                                        \u001b[0m\n",
            "\u001b[1m                                         Total Parameters: 8,649,222 \u001b[0m\u001b[1;2m(34.6 MB)\u001b[0m\u001b[1m                                          \u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "discriminator = Discriminator(7)\n",
        "generator = Generator(7)\n",
        "transition_discriminator = TransitionDiscriminator(7)\n",
        "transition_generator = TransitionGenerator(7)\n",
        "print(discriminator.tabulate({'params': jax.random.PRNGKey(0)}, jnp.ones((10, 256, 256, 3)), console_kwargs={'width': 120}))\n",
        "print(generator.tabulate({'params': jax.random.PRNGKey(0)}, jnp.zeros((10, LATENT_DIM)), console_kwargs={'width': 120}))\n",
        "print(transition_discriminator.tabulate({'params': jax.random.PRNGKey(0)}, jnp.ones((10, 256, 256, 3)), jnp.ones((10, 128, 128, 3)), 0.5, console_kwargs={'width': 120}))\n",
        "print(transition_generator.tabulate({'params': jax.random.PRNGKey(0)}, jnp.zeros((10, LATENT_DIM)), console_kwargs={'width': 120}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV-S3nqYMuau",
        "outputId": "21465a45-54a7-4a3d-9cd8-47d6395772f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[3m                                                 Discriminator Summary                                                  \u001b[0m\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mspectral_norm_stats\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│            │ Discriminator │ \u001b[2mfloat32\u001b[0m[10,4,4,3]   │ \u001b[2mfloat32\u001b[0m[10,1]       │                       │                     │\n",
            "├────────────┼───────────────┼─────────────────────┼─────────────────────┼───────────────────────┼─────────────────────┤\n",
            "│ SN_4_128   │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,4,4,3]   │ \u001b[2mfloat32\u001b[0m[10,4,4,128] │                       │ u0: \u001b[2mfloat32\u001b[0m[1,128]  │\n",
            "│            │               │                     │                     │                       │                     │\n",
            "│            │               │                     │                     │                       │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m         │\n",
            "├────────────┼───────────────┼─────────────────────┼─────────────────────┼───────────────────────┼─────────────────────┤\n",
            "│ Conv_4_128 │ Conv          │ \u001b[2mfloat32\u001b[0m[10,4,4,3]   │ \u001b[2mfloat32\u001b[0m[10,4,4,128] │ bias: \u001b[2mfloat32\u001b[0m[128]    │                     │\n",
            "│            │               │                     │                     │ kernel:               │                     │\n",
            "│            │               │                     │                     │ \u001b[2mfloat32\u001b[0m[3,3,3,128]    │                     │\n",
            "│            │               │                     │                     │                       │                     │\n",
            "│            │               │                     │                     │ \u001b[1m3,584 \u001b[0m\u001b[1;2m(14.3 KB)\u001b[0m       │                     │\n",
            "├────────────┼───────────────┼─────────────────────┼─────────────────────┼───────────────────────┼─────────────────────┤\n",
            "│ SN_1_128   │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,4,4,128] │ \u001b[2mfloat32\u001b[0m[10,1,1,128] │                       │ u0: \u001b[2mfloat32\u001b[0m[1,128]  │\n",
            "│            │               │                     │                     │                       │                     │\n",
            "│            │               │                     │                     │                       │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m         │\n",
            "├────────────┼───────────────┼─────────────────────┼─────────────────────┼───────────────────────┼─────────────────────┤\n",
            "│ Conv_1_128 │ Conv          │ \u001b[2mfloat32\u001b[0m[10,4,4,128] │ \u001b[2mfloat32\u001b[0m[10,1,1,128] │ bias: \u001b[2mfloat32\u001b[0m[128]    │                     │\n",
            "│            │               │                     │                     │ kernel:               │                     │\n",
            "│            │               │                     │                     │ \u001b[2mfloat32\u001b[0m[4,4,128,128]  │                     │\n",
            "│            │               │                     │                     │                       │                     │\n",
            "│            │               │                     │                     │ \u001b[1m262,272 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m      │                     │\n",
            "├────────────┼───────────────┼─────────────────────┼─────────────────────┼───────────────────────┼─────────────────────┤\n",
            "│ SN_Dense   │ SpectralNorm  │ \u001b[2mfloat32\u001b[0m[10,128]     │ \u001b[2mfloat32\u001b[0m[10,1]       │                       │ u0: \u001b[2mfloat32\u001b[0m[1,1]    │\n",
            "│            │               │                     │                     │                       │                     │\n",
            "│            │               │                     │                     │                       │ \u001b[1m1 \u001b[0m\u001b[1;2m(4 B)\u001b[0m             │\n",
            "├────────────┼───────────────┼─────────────────────┼─────────────────────┼───────────────────────┼─────────────────────┤\n",
            "│ Dense      │ Dense         │ \u001b[2mfloat32\u001b[0m[10,128]     │ \u001b[2mfloat32\u001b[0m[10,1]       │ bias: \u001b[2mfloat32\u001b[0m[1]      │                     │\n",
            "│            │               │                     │                     │ kernel:               │                     │\n",
            "│            │               │                     │                     │ \u001b[2mfloat32\u001b[0m[128,1]        │                     │\n",
            "│            │               │                     │                     │                       │                     │\n",
            "│            │               │                     │                     │ \u001b[1m129 \u001b[0m\u001b[1;2m(516 B)\u001b[0m           │                     │\n",
            "├────────────┼───────────────┼─────────────────────┼─────────────────────┼───────────────────────┼─────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m265,985 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m257 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
            "└────────────┴───────────────┴─────────────────────┴─────────────────────┴───────────────────────┴─────────────────────┘\n",
            "\u001b[1m                                                                                                                        \u001b[0m\n",
            "\u001b[1m                                           Total Parameters: 266,242 \u001b[0m\u001b[1;2m(1.1 MB)\u001b[0m\u001b[1m                                           \u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[3m                                                Generator Summary                                                 \u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                      \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│                     │ Generator     │ \u001b[2mfloat32\u001b[0m[10,512]     │ \u001b[2mfloat32\u001b[0m[10,4,4,3]   │                              │\n",
            "├─────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────────┤\n",
            "│ ConvTranspose_4_512 │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,4,4,512] │ \u001b[2mfloat32\u001b[0m[10,4,4,512] │ bias: \u001b[2mfloat32\u001b[0m[512]           │\n",
            "│                     │               │                     │                     │ kernel: \u001b[2mfloat32\u001b[0m[3,3,512,512] │\n",
            "│                     │               │                     │                     │                              │\n",
            "│                     │               │                     │                     │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m           │\n",
            "├─────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────────┤\n",
            "│ ConvTranspose_4_3   │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[10,4,4,512] │ \u001b[2mfloat32\u001b[0m[10,4,4,3]   │ bias: \u001b[2mfloat32\u001b[0m[3]             │\n",
            "│                     │               │                     │                     │ kernel: \u001b[2mfloat32\u001b[0m[3,3,512,3]   │\n",
            "│                     │               │                     │                     │                              │\n",
            "│                     │               │                     │                     │ \u001b[1m13,827 \u001b[0m\u001b[1;2m(55.3 KB)\u001b[0m             │\n",
            "├─────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m2,373,635 \u001b[0m\u001b[1;2m(9.5 MB)\u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\n",
            "└─────────────────────┴───────────────┴─────────────────────┴─────────────────────┴──────────────────────────────┘\n",
            "\u001b[1m                                                                                                                  \u001b[0m\n",
            "\u001b[1m                                       Total Parameters: 2,373,635 \u001b[0m\u001b[1;2m(9.5 MB)\u001b[0m\u001b[1m                                       \u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[3m                                            TransitionDiscriminator Summary                                             \u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mspectral_norm_st…\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
            "│                  │ TransitionDiscri… │ -                 │ \u001b[2mfloat32\u001b[0m[10,1]     │                   │                   │\n",
            "│                  │                   │ \u001b[2mfloat32\u001b[0m[10,8,8,3] │                   │                   │                   │\n",
            "│                  │                   │ -                 │                   │                   │                   │\n",
            "│                  │                   │ \u001b[2mfloat32\u001b[0m[10,4,4,3] │                   │                   │                   │\n",
            "│                  │                   │ - 0.5             │                   │                   │                   │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ SN_8_128         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,8,8,3] │ \u001b[2mfloat32\u001b[0m[10,8,8,1… │                   │ u0:               │\n",
            "│                  │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]    │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m       │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ Conv_8_128       │ Conv              │ \u001b[2mfloat32\u001b[0m[10,8,8,3] │ \u001b[2mfloat32\u001b[0m[10,8,8,1… │ bias:             │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                   │\n",
            "│                  │                   │                   │                   │ kernel:           │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,3,12… │                   │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │ \u001b[1m3,584 \u001b[0m\u001b[1;2m(14.3 KB)\u001b[0m   │                   │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ SN_4_128_large   │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │                   │ u0:               │\n",
            "│                  │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]    │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m       │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ Conv_4_128_large │ Conv              │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ bias:             │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                   │\n",
            "│                  │                   │                   │                   │ kernel:           │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,128,… │                   │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 \u001b[0m   │                   │\n",
            "│                  │                   │                   │                   │ \u001b[1;2mKB)\u001b[0m               │                   │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ SN_4_128         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,4,4,3] │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │                   │ u0:               │\n",
            "│                  │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]    │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m       │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ Conv_4_128       │ Conv              │ \u001b[2mfloat32\u001b[0m[10,4,4,3] │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ bias:             │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                   │\n",
            "│                  │                   │                   │                   │ kernel:           │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,3,12… │                   │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │ \u001b[1m3,584 \u001b[0m\u001b[1;2m(14.3 KB)\u001b[0m   │                   │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ SN_1_128         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ \u001b[2mfloat32\u001b[0m[10,1,1,1… │                   │ u0:               │\n",
            "│                  │                   │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[1,128]    │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │                   │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m       │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ Conv_1_128       │ Conv              │ \u001b[2mfloat32\u001b[0m[10,4,4,1… │ \u001b[2mfloat32\u001b[0m[10,1,1,1… │ bias:             │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128]      │                   │\n",
            "│                  │                   │                   │                   │ kernel:           │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[4,4,128,… │                   │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │ \u001b[1m262,272 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m  │                   │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ SN_Dense         │ SpectralNorm      │ \u001b[2mfloat32\u001b[0m[10,128]   │ \u001b[2mfloat32\u001b[0m[10,1]     │                   │ u0: \u001b[2mfloat32\u001b[0m[1,1]  │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │                   │ \u001b[1m1 \u001b[0m\u001b[1;2m(4 B)\u001b[0m           │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│ Dense            │ Dense             │ \u001b[2mfloat32\u001b[0m[10,128]   │ \u001b[2mfloat32\u001b[0m[10,1]     │ bias: \u001b[2mfloat32\u001b[0m[1]  │                   │\n",
            "│                  │                   │                   │                   │ kernel:           │                   │\n",
            "│                  │                   │                   │                   │ \u001b[2mfloat32\u001b[0m[128,1]    │                   │\n",
            "│                  │                   │                   │                   │                   │                   │\n",
            "│                  │                   │                   │                   │ \u001b[1m129 \u001b[0m\u001b[1;2m(516 B)\u001b[0m       │                   │\n",
            "├──────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┼───────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m                \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m417,153 \u001b[0m\u001b[1;2m(1.7 MB)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m513 \u001b[0m\u001b[1;2m(2.1 KB)\u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m│\n",
            "└──────────────────┴───────────────────┴───────────────────┴───────────────────┴───────────────────┴───────────────────┘\n",
            "\u001b[1m                                                                                                                        \u001b[0m\n",
            "\u001b[1m                                           Total Parameters: 417,666 \u001b[0m\u001b[1;2m(1.7 MB)\u001b[0m\u001b[1m                                           \u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[3m                                              TransitionGenerator Summary                                               \u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                      \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│                     │ TransitionGenerator │ \u001b[2mfloat32\u001b[0m[10,512]     │ - \u001b[2mfloat32\u001b[0m[10,8,8,3] │                              │\n",
            "│                     │                     │                     │ - \u001b[2mfloat32\u001b[0m[10,4,4,3] │                              │\n",
            "├─────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼──────────────────────────────┤\n",
            "│ ConvTranspose_4_512 │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,4,4,512] │ \u001b[2mfloat32\u001b[0m[10,4,4,512] │ bias: \u001b[2mfloat32\u001b[0m[512]           │\n",
            "│                     │                     │                     │                     │ kernel: \u001b[2mfloat32\u001b[0m[3,3,512,512] │\n",
            "│                     │                     │                     │                     │                              │\n",
            "│                     │                     │                     │                     │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m           │\n",
            "├─────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼──────────────────────────────┤\n",
            "│ ConvTranspose_4_3   │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,4,4,512] │ \u001b[2mfloat32\u001b[0m[10,4,4,3]   │ bias: \u001b[2mfloat32\u001b[0m[3]             │\n",
            "│                     │                     │                     │                     │ kernel: \u001b[2mfloat32\u001b[0m[3,3,512,3]   │\n",
            "│                     │                     │                     │                     │                              │\n",
            "│                     │                     │                     │                     │ \u001b[1m13,827 \u001b[0m\u001b[1;2m(55.3 KB)\u001b[0m             │\n",
            "├─────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼──────────────────────────────┤\n",
            "│ ConvTranspose_8_512 │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,8,8,512] │ \u001b[2mfloat32\u001b[0m[10,8,8,512] │ bias: \u001b[2mfloat32\u001b[0m[512]           │\n",
            "│                     │                     │                     │                     │ kernel: \u001b[2mfloat32\u001b[0m[3,3,512,512] │\n",
            "│                     │                     │                     │                     │                              │\n",
            "│                     │                     │                     │                     │ \u001b[1m2,359,808 \u001b[0m\u001b[1;2m(9.4 MB)\u001b[0m           │\n",
            "├─────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼──────────────────────────────┤\n",
            "│ ConvTranspose_8_3   │ ConvTranspose       │ \u001b[2mfloat32\u001b[0m[10,8,8,512] │ \u001b[2mfloat32\u001b[0m[10,8,8,3]   │ bias: \u001b[2mfloat32\u001b[0m[3]             │\n",
            "│                     │                     │                     │                     │ kernel: \u001b[2mfloat32\u001b[0m[3,3,512,3]   │\n",
            "│                     │                     │                     │                     │                              │\n",
            "│                     │                     │                     │                     │ \u001b[1m13,827 \u001b[0m\u001b[1;2m(55.3 KB)\u001b[0m             │\n",
            "├─────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼──────────────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m4,747,270 \u001b[0m\u001b[1;2m(19.0 MB)\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\n",
            "└─────────────────────┴─────────────────────┴─────────────────────┴─────────────────────┴──────────────────────────────┘\n",
            "\u001b[1m                                                                                                                        \u001b[0m\n",
            "\u001b[1m                                         Total Parameters: 4,747,270 \u001b[0m\u001b[1;2m(19.0 MB)\u001b[0m\u001b[1m                                          \u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "discriminator = Discriminator(1)\n",
        "generator = Generator(1)\n",
        "transition_discriminator = TransitionDiscriminator(2)\n",
        "transition_generator = TransitionGenerator(2)\n",
        "print(discriminator.tabulate({'params': jax.random.PRNGKey(0)}, jnp.ones((10, 4, 4, 3)), console_kwargs={'width': 120}))\n",
        "print(generator.tabulate({'params': jax.random.PRNGKey(0)}, jnp.zeros((10, LATENT_DIM)), console_kwargs={'width': 120}))\n",
        "print(transition_discriminator.tabulate({'params': jax.random.PRNGKey(0)}, jnp.ones((10, 8, 8, 3)), jnp.ones((10, 4, 4, 3)), 0.5, console_kwargs={'width': 120}))\n",
        "print(transition_generator.tabulate({'params': jax.random.PRNGKey(0)}, jnp.zeros((10, LATENT_DIM)), console_kwargs={'width': 120}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJKByaYSFKMw"
      },
      "outputs": [],
      "source": [
        "@struct.dataclass\n",
        "class DiscMetrics(metrics.Collection):\n",
        "  accuracy: metrics.Accuracy\n",
        "  loss: metrics.Average.from_output('loss')\n",
        "  prediction: metrics.Average.from_output('prediction')\n",
        "\n",
        "@struct.dataclass\n",
        "class GenMetrics(metrics.Collection):\n",
        "  accuracy: metrics.Accuracy\n",
        "  loss: metrics.Average.from_output('loss')\n",
        "  prediction: metrics.Average.from_output('prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JevWEAgLyMyf"
      },
      "outputs": [],
      "source": [
        "class DiscriminatorTrainState(train_state.TrainState):\n",
        "  metrics: DiscMetrics\n",
        "  spectral_norm_stats: Any\n",
        "  latent_key: jax.random.KeyArray\n",
        "\n",
        "def merge_params(params, existing_params):\n",
        "  result = {}\n",
        "  for param_name in params.keys():\n",
        "    if param_name + \"_large\" in existing_params.keys():\n",
        "      result[param_name] = existing_params[param_name + \"_large\"]\n",
        "    elif param_name in existing_params.keys():\n",
        "      result[param_name] = existing_params[param_name]\n",
        "    else:\n",
        "      result[param_name] = params[param_name]\n",
        "  return result\n",
        "\n",
        "def create_disc_train_state(module, rng, optim, args_fn, existing_params, existing_spectral_norm_stats):\n",
        "  main_key, params_key, latent_key = jax.random.split(rng, num=3)\n",
        "  variables = module.init(params_key, *args_fn(main_key), training=False)\n",
        "  params = merge_params(variables['params'], existing_params)\n",
        "  spectral_norm_stats=merge_params(variables['spectral_norm_stats'], existing_spectral_norm_stats)\n",
        "  return DiscriminatorTrainState.create(\n",
        "      apply_fn=module.apply, params=params, spectral_norm_stats=spectral_norm_stats,\n",
        "      tx=optim, latent_key=latent_key, metrics=DiscMetrics.empty())\n",
        "\n",
        "class GeneratorTrainState(train_state.TrainState):\n",
        "  metrics: GenMetrics\n",
        "  latent_key: jax.random.KeyArray\n",
        "\n",
        "def create_gen_train_state(module, rng, optim, arg_fn, existing_params):\n",
        "  main_key, params_key, latent_key = jax.random.split(rng, num=3)\n",
        "  variables = module.init(params_key, arg_fn(main_key))\n",
        "  params = merge_params(variables['params'], existing_params)\n",
        "  return GeneratorTrainState.create(\n",
        "      apply_fn=module.apply, params=params, tx=optim,\n",
        "      latent_key=latent_key, metrics=GenMetrics.empty())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtxrNuIBNVzr"
      },
      "outputs": [],
      "source": [
        "def sample_latent(batch_size, key):\n",
        "  return jax.random.normal(key, shape=(batch_size, LATENT_DIM))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqZdgH_54YP6"
      },
      "outputs": [],
      "source": [
        "NOISE_LEVEL = 0.10\n",
        "\n",
        "@jax.jit\n",
        "def disc_train_step(d_state, g_state, batch):\n",
        "\n",
        "  def d_loss(d_params):\n",
        "    d_latent_key = jax.random.fold_in(d_state.latent_key, d_state.step)\n",
        "    g_out = g_state.apply_fn({'params': g_state.params}, sample_latent(batch.shape[0], d_latent_key))\n",
        "    d_input = jnp.concatenate([batch, g_out], axis=0)\n",
        "    (d_out, d_updates) = d_state.apply_fn({'params': d_params, 'spectral_norm_stats': d_state.spectral_norm_stats}, d_input, training=True, mutable=['spectral_norm_stats'])\n",
        "    noise = int(batch.shape[0] * NOISE_LEVEL)\n",
        "    d_loss = (d_out[:batch.shape[0]-noise].sum() - d_out[batch.shape[0]+noise:].sum() + d_out[batch.shape[0]:batch.shape[0]+noise].sum() - d_out[batch.shape[0]-noise:batch.shape[0]].sum()) / (2 * batch.shape[0])\n",
        "    return (d_loss, d_updates)\n",
        "\n",
        "  (d_loss, d_updates), d_grads = jax.value_and_grad(d_loss, has_aux=True)(d_state.params)\n",
        "\n",
        "  return (\n",
        "      d_state.apply_gradients(grads=d_grads).replace(spectral_norm_stats=d_updates['spectral_norm_stats'])\n",
        "  )\n",
        "\n",
        "@jax.jit\n",
        "def disc_transition_train_step(d_state, g_state, batch_large, batch_small, alpha):\n",
        "\n",
        "  def d_loss(d_params):\n",
        "    d_latent_key = jax.random.fold_in(d_state.latent_key, d_state.step)\n",
        "    (g_out_large, g_out_small) = g_state.apply_fn({'params': g_state.params}, sample_latent(batch.shape[0], d_latent_key))\n",
        "    (d_input_large, d_input_small) = (jnp.concatenate([batch_large, g_out_large], axis=0), jnp.concatenate([batch_small, g_out_small], axis=0))\n",
        "    (d_out, d_updates) = d_state.apply_fn({'params': d_params, 'spectral_norm_stats': d_state.spectral_norm_stats}, d_input_large, d_input_small, alpha, training=True, mutable=['spectral_norm_stats'])\n",
        "    noise = int(batch.shape[0] * NOISE_LEVEL)\n",
        "    d_loss = (d_out[:batch.shape[0]-noise].sum() - d_out[batch.shape[0]+noise:].sum() + d_out[batch.shape[0]:batch.shape[0]+noise].sum() - d_out[batch.shape[0]-noise:batch.shape[0]].sum()) / (2 * batch.shape[0])\n",
        "    return (d_loss, d_updates)\n",
        "\n",
        "  (d_loss, d_updates), d_grads = jax.value_and_grad(d_loss, has_aux=True)(d_state.params)\n",
        "\n",
        "  return (\n",
        "      d_state.apply_gradients(grads=d_grads).replace(spectral_norm_stats=d_updates['spectral_norm_stats'])\n",
        "  )\n",
        "\n",
        "@jax.jit\n",
        "def gen_train_step(d_state, g_state, batch):\n",
        "\n",
        "  def g_loss(g_params):\n",
        "    g_latent_key = jax.random.fold_in(g_state.latent_key, g_state.step)\n",
        "    g_out = g_state.apply_fn({'params': g_params}, sample_latent(batch.shape[0], g_latent_key))\n",
        "    d_out_fake = d_state.apply_fn({'params': d_state.params, 'spectral_norm_stats': d_state.spectral_norm_stats}, g_out, training=False)\n",
        "    return d_out_fake.mean()\n",
        "\n",
        "  g_loss, g_grads = jax.value_and_grad(g_loss)(g_state.params)\n",
        "\n",
        "  return (\n",
        "      g_state.apply_gradients(grads=g_grads)\n",
        "  )\n",
        "\n",
        "@jax.jit\n",
        "def gen_transition_train_step(d_state, g_state, alpha, batch):\n",
        "\n",
        "  def g_loss(g_params):\n",
        "    g_latent_key = jax.random.fold_in(g_state.latent_key, g_state.step)\n",
        "    (g_out_large, g_out_small)  = g_state.apply_fn({'params': g_params}, sample_latent(batch.shape[0], g_latent_key))\n",
        "    d_out_fake = d_state.apply_fn({'params': d_state.params, 'spectral_norm_stats': d_state.spectral_norm_stats}, g_out_large, g_out_small, alpha, training=False)\n",
        "    return d_out_fake.mean()\n",
        "\n",
        "  g_loss, g_grads = jax.value_and_grad(g_loss)(g_state.params)\n",
        "\n",
        "  return (\n",
        "      g_state.apply_gradients(grads=g_grads)\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWa6JN058fog"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def compute_metrics(d_state, g_state, batch):\n",
        "  g_latent_key = jax.random.fold_in(g_state.latent_key, g_state.step)\n",
        "\n",
        "  g_out = g_state.apply_fn({'params': g_state.params}, sample_latent(batch.shape[0], g_latent_key))\n",
        "  d_out_real = d_state.apply_fn({'params': d_state.params, 'spectral_norm_stats': d_state.spectral_norm_stats}, batch, training=False)\n",
        "  d_out_fake = d_state.apply_fn({'params': d_state.params, 'spectral_norm_stats': d_state.spectral_norm_stats}, g_out, training=False)\n",
        "\n",
        "  avg_pred = jnp.concatenate([d_out_fake, d_out_real], axis=0).mean()\n",
        "\n",
        "  d_logits = jnp.concatenate([jnp.concatenate([avg_pred-d_out_real, d_out_real-avg_pred], axis=1), jnp.concatenate([avg_pred-d_out_fake, d_out_fake-avg_pred], axis=1)], axis=0)\n",
        "  d_labels = jnp.concatenate([jnp.repeat(a=REAL_LABEL, repeats=batch.shape[0]), jnp.repeat(a=FAKE_LABEL, repeats=batch.shape[0])]).astype(jnp.int32)\n",
        "  g_logits = jnp.concatenate([avg_pred-d_out_fake, d_out_fake-avg_pred], axis=1)\n",
        "  g_labels = jnp.repeat(a=REAL_LABEL, repeats=batch.shape[0]).astype(jnp.int32)\n",
        "\n",
        "  d_loss = d_out_real.mean() - d_out_fake.mean()\n",
        "\n",
        "  g_metric_updates = g_state.metrics.single_from_model_output(logits=g_logits, labels=g_labels, loss=d_out_fake.mean(), prediction=d_out_fake)\n",
        "  d_metric_updates = d_state.metrics.single_from_model_output(logits=d_logits, labels=d_labels, loss=d_loss,\n",
        "                                                              prediction=jnp.concatenate([d_out_real, d_out_fake]))\n",
        "  return (\n",
        "      d_state.replace(metrics=d_state.metrics.merge(d_metric_updates)),\n",
        "      g_state.replace(metrics=g_state.metrics.merge(g_metric_updates))\n",
        "  )\n",
        "\n",
        "@jax.jit\n",
        "def compute_metrics_transition(d_state, g_state, batch_large, batch_small, alpha):\n",
        "  g_latent_key = jax.random.fold_in(g_state.latent_key, g_state.step)\n",
        "\n",
        "  (g_out_large, g_out_small) = g_state.apply_fn({'params': g_state.params}, sample_latent(batch_large.shape[0], g_latent_key))\n",
        "  d_out_real = d_state.apply_fn({'params': d_state.params, 'spectral_norm_stats': d_state.spectral_norm_stats}, batch_large, batch_small, alpha, training=False)\n",
        "  d_out_fake = d_state.apply_fn({'params': d_state.params, 'spectral_norm_stats': d_state.spectral_norm_stats}, g_out_large, g_out_small, alpha, training=False)\n",
        "\n",
        "  avg_pred = jnp.concatenate([d_out_fake, d_out_real], axis=0).mean()\n",
        "\n",
        "  d_logits = jnp.concatenate([jnp.concatenate([avg_pred-d_out_real, d_out_real-avg_pred], axis=1), jnp.concatenate([avg_pred-d_out_fake, d_out_fake-avg_pred], axis=1)], axis=0)\n",
        "  d_labels = jnp.concatenate([jnp.repeat(a=REAL_LABEL, repeats=batch.shape[0]), jnp.repeat(a=FAKE_LABEL, repeats=batch.shape[0])]).astype(jnp.int32)\n",
        "  g_logits = jnp.concatenate([avg_pred-d_out_fake, d_out_fake-avg_pred], axis=1)\n",
        "  g_labels = jnp.repeat(a=REAL_LABEL, repeats=batch.shape[0]).astype(jnp.int32)\n",
        "\n",
        "  d_loss = d_out_real.mean() - d_out_fake.mean()\n",
        "\n",
        "  g_metric_updates = g_state.metrics.single_from_model_output(logits=g_logits, labels=g_labels, loss=d_out_fake.mean(), prediction=d_out_fake)\n",
        "  d_metric_updates = d_state.metrics.single_from_model_output(logits=d_logits, labels=d_labels, loss=d_loss,\n",
        "                                                              prediction=jnp.concatenate([d_out_real, d_out_fake]))\n",
        "  return (\n",
        "      d_state.replace(metrics=d_state.metrics.merge(d_metric_updates)),\n",
        "      g_state.replace(metrics=g_state.metrics.merge(g_metric_updates))\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "SJX4tId9QHaF",
        "outputId": "72d85be2-7ce2-45e1-f42e-5ea5e83f8e1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe30823bfd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArR0lEQVR4nO3deXRUZZ7/8U9lqUqCSSAsWSRAwIWWTUVIo7ZimyPQqDj2jMswI409uMVRJt1Ip6cRsZfQOofmtMOgPacV+2e7/lrQn630UQRpZJEtKqI0IKItENySYkulSJ7fH1g3lEmoBKrqLvV+neM51K1bdb9P7q3nfv3e5z7XZ4wxAgAAsEma3QEAAIDURjICAABsRTICAABsRTICAABsRTICAABsRTICAABsRTICAABsRTICAABslWF3AN/U0tKiPXv2KDc3Vz6fz+5wAABAJxhjdODAAZWUlCgtrWu1DsclI3v27FFpaandYQAAgJPwySefqG/fvl36jOOSkdzcXEnHGpOXl2dzNAAAoDOCwaBKS0ut83hXOC4ZiVyaycvLIxkBAMBlTmaIBQNYAQCArUhGAACArUhGAACArUhGAACArUhGAACArUhGAACArUhGAACArUhGAACArUhGAACArbqcjKxcuVJXXXWVSkpK5PP5tGTJEuu9cDismTNnatiwYerWrZtKSkp00003ac+ePfGMGQAAeEiXk5FDhw5pxIgRWrBgQZv3Dh8+rE2bNmnWrFnatGmTnn/+eW3btk1XX311XIIFAADe4zPGmJP+sM+nxYsX65prrulwnfXr12v06NHavXu3+vXrF/M7g8Gg8vPz1dDQwLNpAABwiVM5fyf8QXkNDQ3y+Xzq3r17u++HQiGFQiHrdTAYTHRIAICT8ELtp6r9pN7uMBAHvU4LqPKyM+wOw5LQZKSxsVEzZ87UjTfe2GGWVFNTozlz5iQyDADAKfrqUJOmP1Ork6+lw0kG9u6WGslIOBzWddddJ2OMFi5c2OF61dXVqqqqsl4Hg0GVlpYmKiwAwEk40HhUxkiZ6T7dcslAu8PBKeqR47c7hCgJSUYiicju3bv1+uuvn/DaUSAQUCAQSEQYAIA4aTzaLEk6LZChGeMG2xwNvCbuyUgkEdm+fbuWL1+unj17xnsTAIAkC4VbJElZmek2RwIv6nIycvDgQe3YscN6vWvXLtXW1qqgoEDFxcX6x3/8R23atEkvvfSSmpubtW/fPklSQUGB/H5nlYUAAJ0T+royEshgrkzEX5eTkQ0bNuiyyy6zXkfGe0yZMkX33XefXnzxRUnSueeeG/W55cuXa+zYsScfKQDANqGjxyojgQwqI4i/LicjY8eO1YmmJjmFaUsAAA7VGD5WGcnKpDKC+OOoAgDERGUEiUQyAgCIyRozQmUECcBRBQCIKXI3DQNYkQgcVQCAmCJjRgLc2osEIBkBAMTUOmaE0wbij6MKABATA1iRSCQjAICYmPQMicRRBQCIqZHp4JFAJCMAgJiojCCROKoAADFZt/YyzwgSgKMKABBTIwNYkUAkIwCAmEI8mwYJxFEFAIiJW3uRSCQjAICYGMCKROKoAgDE1MizaZBAHFUAgJgil2mYZwSJQDICAIiJyzRIJI4qAEBMrfOMUBlB/JGMAABiojKCROKoAgDEFOLZNEigDLsDAAAkz/4DjfrD6t061HS0S587HKYygsQhGQGAFPL46o+0YPnOk/psRppPuVmcNhB/HFUAkELqD4clSaMHFGhUWY8uffbc0h7KzcpMRFhIcSQjAJBCIpOXXTa4j24fO8jmaIBjuPgHACkkclcMD7yDk3A0AkAK4YF3cCKSEQBIIa3JCN0/nIOjEQBSSGM4cpmGygicg2QEAFIIlRE4EUcjAKSQUGTyMgawwkE4GgEghTQxgBUORDICACmkdcwI3T+cg6MRAFIIt/bCiUhGACCFMIAVTsTRCAApJDIDKwNY4SQcjQCQIppbjMLNRpKUxWUaOAjJCACkiEhVRKIyAmfhaASAFBH6+om9kuRPp/uHc3A0AkCKaPy6MpKR5lMGyQgchKMRAFJEpDLCc2ngNCQjAJAiuK0XTsURCQApwrqtl2QEDsMRCQApovHryzQBLtPAYUhGACBFUBmBU3FEAkCKCFEZgUN1ORlZuXKlrrrqKpWUlMjn82nJkiVR7xtjdO+996q4uFjZ2dmqqKjQ9u3b4xUvAOAkMYAVTtXlI/LQoUMaMWKEFixY0O77DzzwgH7729/q4Ycf1rp169StWzeNGzdOjY2NpxwsAODkNYa5TANnyujqByZMmKAJEya0+54xRvPnz9fPfvYzTZo0SZL0hz/8QYWFhVqyZIluuOGGU4sWAHDSIpUR5hmB03Q5GTmRXbt2ad++faqoqLCW5efnq7y8XGvWrGk3GQmFQgqFQtbrYDAYz5AApLD/u/Hvem9Pg91hOMbWPcf6VyojcJq4JiP79u2TJBUWFkYtLywstN77ppqaGs2ZMyeeYQCA6oKN+vFzb9sdhiMVdPPbHQIQJa7JyMmorq5WVVWV9ToYDKq0tNTGiAB4QcORsCQpOzNdN188wN5gHCQrI13XjaKPhbPENRkpKiqSJNXV1am4uNhaXldXp3PPPbfdzwQCAQUCgXiGAQDWYM3uOZmaMW6wzdEAOJG4XjgsKytTUVGRli1bZi0LBoNat26dxowZE89NAcAJMVgTcI8uV0YOHjyoHTt2WK937dql2tpaFRQUqF+/fpo+fbp+8Ytf6Mwzz1RZWZlmzZqlkpISXXPNNfGMGwBOyJrgi8GagON1ORnZsGGDLrvsMut1ZLzHlClTtGjRIt1zzz06dOiQbrnlFtXX1+viiy/W0qVLlZWVFb+oASAGpj4H3KPLycjYsWNljOnwfZ/Pp/vvv1/333//KQUGAKeCh8IB7sH/MgDwJCojgHvwKwXgSa3PYaEyAjgdyQgATwpFnsOSSTcHOB2/UgCe1Bi5tZfKCOB4JCMAPMm6tZfKCOB4/EoBeBIDWAH34FcKwJMYwAq4B8kIAE+KPJsmi8s0gOPxKwXgSVRGAPcgGQHgSa3JCN0c4HT8SgF4UiPzjACuwa8UgCeFmGcEcA2SEQCexAysgHvwKwXgSQxgBdyDZASAJ1ljRhjACjgev1IAntQUGTOSSWUEcDqSEQCexK29gHvwKwXgSdazaRjACjgev1IAntQYZgAr4BYkIwA8KVIZ4dk0gPNl2B0AAHTW+o++1Cvv7pOROeF6xkjh5mPrUBkBnI9kBIBrzPzTO/rws0OdXt+fkaYcP8kI4HQkIwBco+FwWJJ04+h+KuiWGXP9CwYUcGsv4AIkIwBcIzKR2W2XDlT/nt1sjgZAvDCyC4BrhJjIDPAkkhEArnC0uUVHWyKDUum6AC/hFw3AFZqaW6x/c4cM4C0kIwBcITKJmURlBPAaftEAXCEyiZk/PU1paT6bowEQTyQjAFwhFObBd4BX8asG4ArWU3iZ3h3wHH7VAFwhMscIg1cB7yEZAeAKVEYA7+JXDcAVIgNYqYwA3kMyAsAVGMAKeBe/agCu0Ph1ZSSLyzSA5/CrBuAKrZURLtMAXkMyAsAVrAGsXKYBPIdfNQBXsG7t5Ym9gOeQjABwhUhlJIvKCOA5/KoBuIJ1ay8DWAHP4VcNwBVax4xwmQbwGpIRAK7QOh083RbgNfyqAbiCNWaEAayA55CMAHAFZmAFvCvuv+rm5mbNmjVLZWVlys7O1qBBg/Tzn/9cxph4bwpACml9Ng3JCOA1GfH+wl//+tdauHChHn/8cQ0ZMkQbNmzQ1KlTlZ+fr7vuuivemwOQIhojlREu0wCeE/dkZPXq1Zo0aZImTpwoSRowYICeeuopvfXWW/HeFIAUEuLZNIBnxT0ZufDCC/W73/1Of/vb33TWWWfp7bff1qpVqzRv3rx21w+FQgqFQtbrYDAY75AAT/u0/oieWLvbutvEq7bXHZTErb2AF8U9GfnJT36iYDCowYMHKz09Xc3NzfrlL3+pyZMnt7t+TU2N5syZE+8wgJTx8Iqd+j9rd9sdRtL0yPHbHQKAOIt7MvLss8/qj3/8o5588kkNGTJEtbW1mj59ukpKSjRlypQ261dXV6uqqsp6HQwGVVpaGu+wAM+qPxKWJH3nzF4a3jff5mgSqyg/W+VlBXaHASDO4p6MzJgxQz/5yU90ww03SJKGDRum3bt3q6ampt1kJBAIKBAIxDsMIGVELs+MH1qkyeX9bY4GALou7iPBDh8+rLS06K9NT09XS0tLvDcFQMc/QI6xFADcKe6Vkauuukq//OUv1a9fPw0ZMkSbN2/WvHnzdPPNN8d7UwAkhcI8QA6Au8U9GXnooYc0a9Ys3XHHHdq/f79KSkp066236t577433pgCIB8gBcL+4JyO5ubmaP3++5s+fH++vBtCOyJgR5t8A4Fb0XoDLNVEZAeByJCOAy7VepuHnDMCd6L0Al7MeIMdlGgAuRe8FuFzkAXLc2gvArUhGAJejMgLA7ei9ABdrbjEKNxtJDGAF4F4kI4CLRe6kkRjACsC96L0AF4vMMSKRjABwL3ovwMUit/VmpPmUkc7PGYA70XsBLmYNXqUqAsDF6MEAF4vc1hvIZPAqAPciGQFcLFIZyaIyAsDF6MEAF7OmgqcyAsDFSEYAFwuFeS4NAPejBwNcLHJrL8kIADejBwNcjMs0ALyAZARwMW7tBeAF9GCAi1mVEZ5LA8DFSEYAF7PGjPDEXgAuRg8GuFikMpJFZQSAi2XYHQCA9u0/0Kg/rN6tQ01HO1yn9pN6SVRGALgbyQjgUI+v/kgLlu/s1LoFOf4ERwMAiUMyAjhU/eGwJGl0WYFGDejR4Xo5/gzdMKo0WWEBQNyRjAAOFXkI3ncH99Ftlw6yORoASBwuNAMOxUPwAKQKejnAoZhdFUCqIBkBHKp1QjN+pgC8jV4OcKjIhGZZVEYAeBzJCOBQVEYApAp6OcChQpGp3pldFYDHkYwADtVkDWDlZwrA2+jlAIeyxoxQGQHgcSQjgEOFqIwASBH0coBDMYAVQKqglwMcKjIDKwNYAXgdyQjgQM0tRuFmI0nK4jINAI+jlwMcKFIVkaiMAPA+khHAgUJfP7FXkvyMGQHgcfRygAM1fl0ZyUz3KT3NZ3M0AJBYJCOAA0UqI8wxAiAVkIwADsQcIwBSCT0d4EDc1gsglZCMAA7UGGbCMwCpg54OcCCrMpJJZQSA95GMAA4UojICIIUkpKf79NNP9S//8i/q2bOnsrOzNWzYMG3YsCERmwI8iefSAEglGfH+wq+++koXXXSRLrvsMr3yyivq3bu3tm/frh49esR7U4BnNYa5TAMgdcQ9Gfn1r3+t0tJSPfbYY9aysrKyeG8G8LRIZSSLygiAFBD3ZOTFF1/UuHHj9E//9E964403dPrpp+uOO+7QtGnT2l0/FAopFApZr4PBYLxDQgoKHW3W71ft0mcHQrFXdqCte479DqiMAEgFcU9GPvzwQy1cuFBVVVX66U9/qvXr1+uuu+6S3+/XlClT2qxfU1OjOXPmxDsMpLjlH3ymB5ZuszuMU1aQk2l3CACQcD5jjInnF/r9fl1wwQVavXq1teyuu+7S+vXrtWbNmjbrt1cZKS0tVUNDg/Ly8uIZGlLIM+s/1sw/vasBPXM0cXix3eGclKyMdF03qlSFeVl2hwIAMQWDQeXn55/U+TvulZHi4mKdc845Ucu+9a1v6U9/+lO76wcCAQUCgXiHgRQXmTTsnJI8zRg32OZoAAAnEvfRcRdddJG2bYsuj//tb39T//79470poEORScN40BwAOF/ck5H/+I//0Nq1a/WrX/1KO3bs0JNPPqnf/e53qqysjPemgA5Zk4bxoDkAcLy499SjRo3S4sWL9dRTT2no0KH6+c9/rvnz52vy5Mnx3hTQodZJw6iMAIDTxX3MiCRdeeWVuvLKKxPx1UCntE4aRmUEAJyOnhqeRGUEANyDZASeZD31lhlMAcDx6KnhSTxoDgDcg54anhQZM5LFdOoA4HgkI/AkKiMA4B701PCk1nlGqIwAgNORjMCTGMAKAO5BTw1PijybhjEjAOB8JCPwJCojAOAe9NTwJAawAoB70FPDkyKXaZiBFQCcj2QEnhS5TJPFs2kAwPHoqeFJ1mUaBrACgOORjMBzjDFqYswIALgGPTU8J1IVkUhGAMAN6KnhOZHZVyXmGQEANyAZgedEBq+m+aSMNJ/N0QAAYiEZgee0zjGSLp+PZAQAnI5kBJ7TGP569lVu6wUAV6C3hudEKiNZTHgGAK6QYXcAwMmoP9ykR9/8SAcaw23e238gJInKCAC4BckIXOm5DX/Xb5dtP+E6PXL8SYoGAHAqSEbgSvVHmiRJI/rm6+Ize7V5P83n0/eGFSc7LADASSAZgStFHoT37UE9NWPcYJujAQCcCi6qw5WsB+ExSBUAXI9kBK4UmWWVQaoA4H705HCl4yc2AwC4G8kIXCkysVkWlREAcD16crgSlREA8A6SEbhSZABrIINDGADcjp4crtRaGeEQBgC3oyeHK0XmGcnK5DINALgdyQhcics0AOAd9ORwpdZ5RqiMAIDbkYzAlRgzAgDeQU8OVwpZ84xQGQEAtyMZgStRGQEA76Anh+u0tBg1NZOMAIBX0JPDdSJVEYkBrADgBSQjcJ3Ibb2SlEVlBABcj54crhOpjKSn+ZSRziEMAG5HTw7XseYYoSoCAJ5Abw7XaWT2VQDwFHpzuE6I59IAgKeQjMB1eC4NAHhLwnvzuXPnyufzafr06YneFFJE64RnVEYAwAsSmoysX79ejzzyiIYPH57IzSDFNH49FXwgk8oIAHhBwnrzgwcPavLkyfrf//1f9ejRI1GbQQqKVEayqIwAgCdkJOqLKysrNXHiRFVUVOgXv/hFh+uFQiGFQiHrdTAYTFRI6IJnN3yi9/c6c1/s/OyQJCojAOAVCUlGnn76aW3atEnr16+PuW5NTY3mzJmTiDBwkvbUH9E9//cdu8OIqUeO3+4QAABxEPdk5JNPPtHdd9+tV199VVlZWTHXr66uVlVVlfU6GAyqtLQ03mGhC+oPhyVJOf50Tb1ogL3BdCAzPU3fP7+v3WEAAOIg7snIxo0btX//fp1//vnWsubmZq1cuVL//d//rVAopPT01mv9gUBAgUAg3mHgFEQmFSvo5teMcYNtjgYA4HVxT0Yuv/xyvfvuu1HLpk6dqsGDB2vmzJlRiQiciUnFAADJFPdkJDc3V0OHDo1a1q1bN/Xs2bPNcjgTk4oBAJKJsw3aaJ1UjMMDAJB4Cbu193grVqxIxmYQJ5FJxbhMAwBIBv7XF21QGQEAJBNnG7TBs18AAMlEMoI2Qjz7BQCQRJxt0AbPfgEAJBPJCNqgMgIASCbONmiDAawAgGTibIM2GMAKAEgmkhG00TrPCIcHACDxONugDSojAIBkIhlBG9azaaiMAACSgLMN2mgMM4AVAJA8nG3QRqQywrNpAADJQDKCNkJURgAAScTZBm0wgBUAkEwkI2gjcmsvlREAQDJwtkEbVmWEMSMAgCQgGUEb1q29VEYAAEnA2QZtWE/tZZ4RAEAScLZBG61jRrhMAwBIPJIRRDHGHDdmhMMDAJB4GXYHAHs0hpv1+1W79PnBUNRyY479J1EZAQAkB8lIinp1a50e/Mu2Dt/PykxTNnfTAACSgGQkRdUfCUuSBvXupvFDi9q8P7qsp/zcTQMASAKSkRQV+nqQ6rDT8zVj3GCbowEApDL+1zdFtd6+y6UYAIC9SEZSVIgp3wEADsGZKEUx5TsAwClIRlJUZGKzLCojAACbcSZKUVRGAABOQTKSoqxkhMoIAMBmnIlSFE/mBQA4BWeiFNUY5jINAMAZSEZSFJURAIBTcCZKUaFIZYSH4QEAbEYykqJa76bhEAAA2IszUYpqnWeEyggAwF4kIymKyggAwCk4E6UoBrACAJyCM1GKamQAKwDAIUhGUlSkMpLFZRoAgM04E6UgY8xx08FTGQEA2ItkJAWFm42MOfZvBrACAOzGmSgFNX59iUZiACsAwH6ciVJQZPZVn0/yp3MIAADsxZkoBR1/W6/P57M5GgBAqot7MlJTU6NRo0YpNzdXffr00TXXXKNt27bFezM4BQxeBQA4SdyTkTfeeEOVlZVau3atXn31VYXDYV1xxRU6dOhQvDeFkxSZCp7xIgAAJ8iI9xcuXbo06vWiRYvUp08fbdy4UZdcckm8N4eTEKmMZGVSGQEA2C/uycg3NTQ0SJIKCgrafT8UCikUClmvg8FgokOy3Tt/r9cLtXvUErm/Nsnqgo2SqIwAAJwhoclIS0uLpk+frosuukhDhw5td52amhrNmTMnkWE4zuwX39Pmj+vtDkM9uvntDgEAgMQmI5WVldqyZYtWrVrV4TrV1dWqqqqyXgeDQZWWliYyLNs1HA5Lkq4973QVd8+yJYY0n09XDi+xZdsAABwvYcnInXfeqZdeekkrV65U3759O1wvEAgoEAgkKgxHigwgnXLhAI0o7W5vMAAA2CzuyYgxRv/+7/+uxYsXa8WKFSorK4v3JlyPAaQAALSKezJSWVmpJ598Ui+88IJyc3O1b98+SVJ+fr6ys7PjvTlXap3ngwGkAADE/Wy4cOFCNTQ0aOzYsSouLrb+e+aZZ+K9KdeyZkDlIXUAACTmMg061txiFG4+9jfKYgZUAAB4Nk2yhY5/Yi6VEQAASEaSLfLEXIkn5gIAIJGMJF1k8GpGmk8ZJCMAAJCMJFtkjhFu6wUA4BiSkSTjtl4AAKJxRkwy67ZekhEAACSRjCSdVRnhMg0AAJJIRpIuMmaEyggAAMdwRkyyyK29VEYAADiGZCTJGMAKAEA0zohJxmUaAACicUZMskhlhHlGAAA4hmQkybi1FwCAaJwRk6x1zAiVEQAAJJKRpLPGjPDEXgAAJJGMJJ01ZoTKCAAAkkhGkq51nhH+9AAASCQjSccAVgAAonFGTLLGMANYAQA4HslIkkUqI1lcpgEAQJKUYXcAXmaM0eOrP9LuLw9by979tEESlREAACJIRhJoy6dB3ff/trb7XkG3zCRHAwCAM5GMJFD9kSZJUq/T/Lp+VKm1vNdpAX13cKFdYQEA4CgkIwkUGax6eo8czRg32OZoAABwJkZRJpA1WJXbeAEA6BBnyQRqneCMwaoAAHSEZCSBWh+Kx58ZAICOcJZMoMhD8bKojAAA0CGSkQSiMgIAQGycJROI59AAABAbZ8kEaq2McJkGAICOkIwkUOuYEf7MAAB0hLNkAlEZAQAgNpKRBGqdZ4Q/MwAAHeEsmUAMYAUAIDbOkgkUeTYN84wAANAxkpEEojICAEBsnCUTiAGsAADERjKSQKEwlREAAGLhLJlAkcoIY0YAAOgYyUgCWZdpuLUXAIAOcZZMIC7TAAAQG2fJBGpkACsAADGRjCRQiGfTAAAQE2fJBOLWXgAAYktYMrJgwQINGDBAWVlZKi8v11tvvZWoTTnS0eYWHW0xkhgzAgDAiSTkLPnMM8+oqqpKs2fP1qZNmzRixAiNGzdO+/fvT8TmHClSFZG4mwYAgBNJyFly3rx5mjZtmqZOnapzzjlHDz/8sHJycvToo48mYnOOFJWMcJkGAIAOZcT7C5uamrRx40ZVV1dby9LS0lRRUaE1a9a0WT8UCikUClmvg8FgvEOSJH1+MKQFy3ck5Lvbczh0bPBqZrpP6Wm+pG0XAAC3iXsy8vnnn6u5uVmFhYVRywsLC/XBBx+0Wb+mpkZz5syJdxhtBI+E9dibHyV8O9/UI8ef9G0CAOAmcU9Guqq6ulpVVVXW62AwqNLS0rhvp3uOX5WXDYr798Yy9uw+Sd8mAABuEvdkpFevXkpPT1ddXV3U8rq6OhUVFbVZPxAIKBAIxDuMNgq6+TVj3OCEbwcAAHRN3Aew+v1+jRw5UsuWLbOWtbS0aNmyZRozZky8NwcAAFwuIZdpqqqqNGXKFF1wwQUaPXq05s+fr0OHDmnq1KmJ2BwAAHCxhCQj119/vT777DPde++92rdvn84991wtXbq0zaBWAAAAnzHG2B3E8YLBoPLz89XQ0KC8vDy7wwEAAJ1wKudvpgYFAAC2IhkBAAC2IhkBAAC2IhkBAAC2IhkBAAC2IhkBAAC2IhkBAAC2IhkBAAC2IhkBAAC2Ssh08KciMiFsMBi0ORIAANBZkfP2yUzs7rhk5MCBA5Kk0tJSmyMBAABddeDAAeXn53fpM457Nk1LS4v27Nmj3Nxc+Xy+uH53MBhUaWmpPvnkE08+98br7ZO830avt0/yfhu93j7J+230evukxLTRGKMDBw6opKREaWldGwXiuMpIWlqa+vbtm9Bt5OXlefYAk7zfPsn7bfR6+yTvt9Hr7ZO830avt0+Kfxu7WhGJYAArAACwFckIAACwVUolI4FAQLNnz1YgELA7lITwevsk77fR6+2TvN9Gr7dP8n4bvd4+yXltdNwAVgAAkFpSqjICAACch2QEAADYimQEAADYimQEAADYKmWSkQULFmjAgAHKyspSeXm53nrrLbtDUk1NjUaNGqXc3Fz16dNH11xzjbZt2xa1ztixY+Xz+aL+u+2226LW+fjjjzVx4kTl5OSoT58+mjFjho4ePRq1zooVK3T++ecrEAjojDPO0KJFi9rEk4i/0X333dcm/sGDB1vvNzY2qrKyUj179tRpp52m73//+6qrq3NN+yRpwIABbdro8/lUWVkpyX37cOXKlbrqqqtUUlIin8+nJUuWRL1vjNG9996r4uJiZWdnq6KiQtu3b49a58svv9TkyZOVl5en7t2764c//KEOHjwYtc4777yj73znO8rKylJpaakeeOCBNrE899xzGjx4sLKysjRs2DC9/PLLXY6lq20Mh8OaOXOmhg0bpm7duqmkpEQ33XST9uzZE/Ud7e33uXPnOqKNsfbhD37wgzaxjx8/PmodJ+/DWO1r7/fo8/n04IMPWus4ef915tzgpL6zM7HEZFLA008/bfx+v3n00UfNe++9Z6ZNm2a6d+9u6urqbI1r3Lhx5rHHHjNbtmwxtbW15nvf+57p16+fOXjwoLXOpZdeaqZNm2b27t1r/dfQ0GC9f/ToUTN06FBTUVFhNm/ebF5++WXTq1cvU11dba3z4YcfmpycHFNVVWW2bt1qHnroIZOenm6WLl1qrZOov9Hs2bPNkCFDouL/7LPPrPdvu+02U1paapYtW2Y2bNhgvv3tb5sLL7zQNe0zxpj9+/dHte/VV181kszy5cuNMe7bhy+//LL5z//8T/P8888bSWbx4sVR78+dO9fk5+ebJUuWmLfffttcffXVpqyszBw5csRaZ/z48WbEiBFm7dq15q9//as544wzzI033mi939DQYAoLC83kyZPNli1bzFNPPWWys7PNI488Yq3z5ptvmvT0dPPAAw+YrVu3mp/97GcmMzPTvPvuu12KpattrK+vNxUVFeaZZ54xH3zwgVmzZo0ZPXq0GTlyZNR39O/f39x///1R+/X4366dbYy1D6dMmWLGjx8fFfuXX34ZtY6T92Gs9h3frr1795pHH33U+Hw+s3PnTmsdJ++/zpwbnNR3xoqlM1IiGRk9erSprKy0Xjc3N5uSkhJTU1NjY1Rt7d+/30gyb7zxhrXs0ksvNXfffXeHn3n55ZdNWlqa2bdvn7Vs4cKFJi8vz4RCIWOMMffcc48ZMmRI1Oeuv/56M27cOOt1ov5Gs2fPNiNGjGj3vfr6epOZmWmee+45a9n7779vJJk1a9a4on3tufvuu82gQYNMS0uLMcbd+/CbHX1LS4spKioyDz74oLWsvr7eBAIB89RTTxljjNm6dauRZNavX2+t88orrxifz2c+/fRTY4wx//M//2N69Ohhtc8YY2bOnGnOPvts6/V1111nJk6cGBVPeXm5ufXWWzsdy8m0sT1vvfWWkWR2795tLevfv7/5zW9+0+FnnNLGjpKRSZMmdfgZN+3Dzuy/SZMmme9+97tRy9yy/4xpe25wUt/ZmVg6w/OXaZqamrRx40ZVVFRYy9LS0lRRUaE1a9bYGFlbDQ0NkqSCgoKo5X/84x/Vq1cvDR06VNXV1Tp8+LD13po1azRs2DAVFhZay8aNG6dgMKj33nvPWuf49kfWibQ/0X+j7du3q6SkRAMHDtTkyZP18ccfS5I2btyocDgctd3BgwerX79+1nbd0L7jNTU16YknntDNN98c9aBHt+/DiF27dmnfvn1R28nPz1d5eXnUPuvevbsuuOACa52KigqlpaVp3bp11jqXXHKJ/H5/VHu2bdumr776qlNt7kws8dLQ0CCfz6fu3btHLZ87d6569uyp8847Tw8++GBUCdzpbVyxYoX69Omjs88+W7fffru++OKLqNi9sg/r6ur05z//WT/84Q/bvOeW/ffNc4OT+s7OxNIZjntQXrx9/vnnam5ujtohklRYWKgPPvjApqjaamlp0fTp03XRRRdp6NCh1vJ//ud/Vv/+/VVSUqJ33nlHM2fO1LZt2/T8889Lkvbt29du2yLvnWidYDCoI0eO6KuvvkrY36i8vFyLFi3S2Wefrb1792rOnDn6zne+oy1btmjfvn3y+/1tOvjCwsKYsTulfd+0ZMkS1dfX6wc/+IG1zO378HiReNrbzvGx9unTJ+r9jIwMFRQURK1TVlbW5jsi7/Xo0aPDNh//HbFiiYfGxkbNnDlTN954Y9QDxe666y6df/75Kigo0OrVq1VdXa29e/dq3rx5jm/j+PHjde2116qsrEw7d+7UT3/6U02YMEFr1qxRenq6p/bh448/rtzcXF177bVRy92y/9o7Nzip7+xMLJ3h+WTELSorK7VlyxatWrUqavktt9xi/XvYsGEqLi7W5Zdfrp07d2rQoEHJDrPLJkyYYP17+PDhKi8vV//+/fXss88qOzvbxsgS4/e//70mTJigkpISa5nb92EqC4fDuu6662SM0cKFC6Peq6qqsv49fPhw+f1+3XrrraqpqXHMFNsdueGGG6x/Dxs2TMOHD9egQYO0YsUKXX755TZGFn+PPvqoJk+erKysrKjlbtl/HZ0bvMbzl2l69eql9PT0NiN76+rqVFRUZFNU0e6880699NJLWr58ufr27XvCdcvLyyVJO3bskCQVFRW127bIeydaJy8vT9nZ2Un9G3Xv3l1nnXWWduzYoaKiIjU1Nam+vr7D7bqpfbt379Zrr72mf/u3fzvhem7eh5HvOtF2ioqKtH///qj3jx49qi+//DIu+/X492PFcioiicju3bv16quvxnzMenl5uY4ePaqPPvrohPEfH7vdbYwYOHCgevXqFXVMemEf/vWvf9W2bdti/iYlZ+6/js4NTuo7OxNLZ3g+GfH7/Ro5cqSWLVtmLWtpadGyZcs0ZswYGyM7dsvXnXfeqcWLF+v1119vUxJsT21trSSpuLhYkjRmzBi9++67UR1HpOM855xzrHWOb39knUj7k/k3OnjwoHbu3Kni4mKNHDlSmZmZUdvdtm2bPv74Y2u7bmrfY489pj59+mjixIknXM/N+7CsrExFRUVR2wkGg1q3bl3UPquvr9fGjRutdV5//XW1tLRYidiYMWO0cuVKhcPhqPacffbZ6tGjR6fa3JlYTlYkEdm+fbtee+019ezZM+ZnamtrlZaWZl3ecHobj/f3v/9dX3zxRdQx6fZ9KB2rVI4cOVIjRoyIua6T9l+sc4OT+s7OxNIpnR7q6mJPP/20CQQCZtGiRWbr1q3mlltuMd27d48aZWyH22+/3eTn55sVK1ZE3V52+PBhY4wxO3bsMPfff7/ZsGGD2bVrl3nhhRfMwIEDzSWXXGJ9R+T2rSuuuMLU1taapUuXmt69e7d7+9aMGTPM+++/bxYsWNDu7VuJ+Bv96Ec/MitWrDC7du0yb775pqmoqDC9evUy+/fvN8YcuyWsX79+5vXXXzcbNmwwY8aMMWPGjHFN+yKam5tNv379zMyZM6OWu3EfHjhwwGzevNls3rzZSDLz5s0zmzdvtu4kmTt3runevbt54YUXzDvvvGMmTZrU7q295513nlm3bp1ZtWqVOfPMM6NuC62vrzeFhYXmX//1X82WLVvM008/bXJyctrcNpmRkWH+67/+y7z//vtm9uzZ7d42GSuWrraxqanJXH311aZv376mtrY26rcZuQth9erV5je/+Y2pra01O3fuNE888YTp3bu3uemmmxzRxhO178CBA+bHP/6xWbNmjdm1a5d57bXXzPnnn2/OPPNM09jY6Ip9GOsYNebYrbk5OTlm4cKFbT7v9P0X69xgjLP6zlixdEZKJCPGGPPQQw+Zfv36Gb/fb0aPHm3Wrl1rd0hGUrv/PfbYY8YYYz7++GNzySWXmIKCAhMIBMwZZ5xhZsyYETVHhTHGfPTRR2bChAkmOzvb9OrVy/zoRz8y4XA4ap3ly5ebc8891/j9fjNw4EBrG8dLxN/o+uuvN8XFxcbv95vTTz/dXH/99WbHjh3W+0eOHDF33HGH6dGjh8nJyTH/8A//YPbu3eua9kX85S9/MZLMtm3bopa7cR8uX7683eNyypQpxphjtyvOmjXLFBYWmkAgYC6//PI27f7iiy/MjTfeaE477TSTl5dnpk6dag4cOBC1zttvv20uvvhiEwgEzOmnn27mzp3bJpZnn33WnHXWWcbv95shQ4aYP//5z1HvdyaWrrZx165dHf42I3PHbNy40ZSXl5v8/HyTlZVlvvWtb5lf/epXUSdzO9t4ovYdPnzYXHHFFaZ3794mMzPT9O/f30ybNq1N0urkfRjrGDXGmEceecRkZ2eb+vr6Np93+v6LdW4wxll9Z2diicX3dcMBAABs4fkxIwAAwNlIRgAAgK1IRgAAgK1IRgAAgK1IRgAAgK1IRgAAgK1IRgAAgK1IRgAAgK1IRgAAgK1IRgAAgK1IRgAAgK1IRgAAgK3+PzF/0A15N/aSAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "INITIAL_STEPS = 12_500\n",
        "TRANSITION = 0.2\n",
        "MULTIPLIER = 1.2\n",
        "\n",
        "transitions = []\n",
        "all_steps = 0\n",
        "steps = INITIAL_STEPS\n",
        "\n",
        "transitions.append(0)\n",
        "\n",
        "for layer in range(MAX_LAYERS-1):\n",
        "  all_steps += int(steps)\n",
        "  transitions.append(all_steps)\n",
        "  all_steps += int(steps * TRANSITION)\n",
        "  transitions.append(all_steps)\n",
        "  steps *= MULTIPLIER\n",
        "\n",
        "X = [400 * x for x in range(500)]\n",
        "plt.plot(X, [np.searchsorted(transitions, x, 'right') - 1 for x in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "qgJonbtF71-H",
        "outputId": "a7c66745-b8c7-4aa2-a052-a60d5a4728eb"
      },
      "outputs": [],
      "source": [
        "run_id = f'{int(time.time())}'\n",
        "logdir = f'runs_{run_id}'\n",
        "writer = SummaryWriter(logdir)\n",
        "port = 6000 + int(time.time()) % 40\n",
        "%load_ext tensorboard\n",
        "%tensorboard --port={port} --logdir={logdir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fSaMR-Alf6q"
      },
      "outputs": [],
      "source": [
        "num_steps_per_checkpoint = 500\n",
        "\n",
        "for img in glob.glob(\"image*png\"):\n",
        "  os.remove(img)\n",
        "\n",
        "for ckp in glob.glob(\"d_checkpoint_*.msgpack\"):\n",
        "  os.remove(ckp)\n",
        "\n",
        "for ckp in glob.glob(\"g_checkpoint_*.msgpack\"):\n",
        "  os.remove(ckp)\n",
        "\n",
        "latents = sample_latent(4, key=jax.random.PRNGKey(0))\n",
        "\n",
        "skipped_train_steps = 0\n",
        "skipped_test_steps = 0\n",
        "\n",
        "step = -1\n",
        "layer = None\n",
        "\n",
        "d_state = None\n",
        "g_state = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVTan1-JXhAv"
      },
      "outputs": [],
      "source": [
        "def small_batch(large_batch):\n",
        "  return jax.image.resize(large_batch, shape=(large_batch.shape[0], int(large_batch.shape[1]/2), int(large_batch.shape[2]/2), large_batch.shape[3]), method=\"linear\")\n",
        "\n",
        "while step < 200_000:\n",
        "  step += 1\n",
        "\n",
        "  if step in transitions:\n",
        "    layer = transitions.index(step)\n",
        "    resindex = int((layer+1)/2)\n",
        "    resolution = 4 * (2 ** resindex)\n",
        "\n",
        "    existing_d_params = {}\n",
        "    existing_spectral_norm_stats = {}\n",
        "    if d_state:\n",
        "      existing_d_params = d_state.params\n",
        "      existing_spectral_norm_stats = d_state.spectral_norm_stats\n",
        "\n",
        "    existing_g_params = {}\n",
        "    if g_state:\n",
        "      existing_g_params = g_state.params\n",
        "\n",
        "    learning_rate = 1e-4 * batch_sizes[resindex] / 64\n",
        "    if layer % 2 == 0:\n",
        "      discriminator = Discriminator(1+resindex)\n",
        "      generator = Generator(1+resindex)\n",
        "      d_state = create_disc_train_state(discriminator, jax.random.PRNGKey(1), optax.rmsprop(learning_rate), lambda key: (jax.random.normal(key, shape=[6, resolution, resolution, 3]),), existing_d_params, existing_spectral_norm_stats)\n",
        "      g_state = create_gen_train_state(generator, jax.random.PRNGKey(0), optax.rmsprop(learning_rate), lambda key: jax.random.normal(key, shape=(16, LATENT_DIM)), existing_g_params)\n",
        "    else:\n",
        "      discriminator = TransitionDiscriminator(1+resindex)\n",
        "      generator = TransitionGenerator(1+resindex)\n",
        "      d_state = create_disc_train_state(discriminator, jax.random.PRNGKey(1), optax.rmsprop(learning_rate), lambda key: (jax.random.normal(key, shape=[6, resolution, resolution, 3]), jax.random.normal(key, shape=[6, int(resolution/2), int(resolution/2), 3]), 1.), existing_d_params, existing_spectral_norm_stats)\n",
        "      g_state = create_gen_train_state(generator, jax.random.PRNGKey(0), optax.rmsprop(learning_rate), lambda key: jax.random.normal(key, shape=(16, LATENT_DIM)), existing_g_params)\n",
        "\n",
        "    ds_iter = datasets[resindex][0].as_numpy_iterator()\n",
        "\n",
        "  if layer % 2 == 1:\n",
        "    alpha = (transitions[layer+1] - step) / (transitions[layer+1] - transitions[layer])\n",
        "\n",
        "  batch = ds_iter.next()\n",
        "\n",
        "  if batch.shape[0] != batch_sizes[resindex]:\n",
        "    # TODO: figure out how to drop_remainder with disk + TFDS dataset\n",
        "    skipped_train_steps += 1\n",
        "    continue\n",
        "\n",
        "  if step % num_steps_per_checkpoint == 0:\n",
        "    d_train_metrics = d_state.metrics\n",
        "    d_state = d_state.replace(metrics=DiscMetrics.empty())\n",
        "\n",
        "    g_train_metrics = g_state.metrics\n",
        "    g_state = g_state.replace(metrics=GenMetrics.empty())\n",
        "\n",
        "    # Take expensive model checkpoints rarely.\n",
        "    if step % (5 * num_steps_per_checkpoint) == 0:\n",
        "      with open(f'd_checkpoint_{step}.msgpack', 'wb') as outfile:\n",
        "        outfile.write(msgpack_serialize(to_state_dict(d_state)))\n",
        "      with open(f'g_checkpoint_{step}.msgpack', 'wb') as outfile:\n",
        "        outfile.write(msgpack_serialize(to_state_dict(g_state)))\n",
        "\n",
        "    d_test_state = d_state\n",
        "    d_state = d_state.replace(metrics=DiscMetrics.empty())\n",
        "\n",
        "    g_test_state = g_state\n",
        "    g_state = g_state.replace(metrics=GenMetrics.empty())\n",
        "\n",
        "    for test_batch in datasets[resindex][1].as_numpy_iterator():\n",
        "      if test_batch.shape[0] != batch_sizes[resindex]:\n",
        "        # TODO: figure out how to drop_remainder with disk + TFDS dataset\n",
        "        skipped_test_steps += 1\n",
        "        continue\n",
        "      if layer % 2 == 0:\n",
        "        d_test_state, g_test_state = compute_metrics(d_test_state, g_test_state, test_batch)\n",
        "      else:\n",
        "        d_test_state, g_test_state = compute_metrics_transition(d_test_state, g_test_state, test_batch, small_batch(test_batch), alpha)\n",
        "\n",
        "    writer.add_scalars('Discriminator/Loss', {'train': d_train_metrics.loss.compute().tolist(), 'test': d_test_state.metrics.loss.compute().tolist()}, step)\n",
        "    writer.add_scalars('Discriminator/Accuracy', {'train': d_train_metrics.accuracy.compute().tolist(), 'test': d_test_state.metrics.accuracy.compute().tolist()}, step)\n",
        "\n",
        "    writer.add_scalars('Generator/Loss', {'train': g_train_metrics.loss.compute().tolist(), 'test': g_test_state.metrics.loss.compute().tolist()}, step)\n",
        "    writer.add_scalars('Generator/Accuracy', {'train': g_train_metrics.accuracy.compute().tolist(), 'test': g_test_state.metrics.accuracy.compute().tolist()}, step)\n",
        "\n",
        "    writer.add_scalars('Prediction/Discriminator', {'train': d_train_metrics.prediction.compute().tolist(), 'test': d_test_state.metrics.prediction.compute().tolist()}, step)\n",
        "    writer.add_scalars('Prediction/Generator', {'train': g_train_metrics.prediction.compute().tolist(), 'test': g_test_state.metrics.prediction.compute().tolist()}, step)\n",
        "\n",
        "    writer.add_scalars('Skipped Steps', {'train': skipped_train_steps, 'test': skipped_test_steps}, step)\n",
        "\n",
        "    # To measure training walltime speed.\n",
        "    writer.add_scalar('Steps', step, step)\n",
        "\n",
        "    if layer % 2 == 1:\n",
        "      writer.add_scalar('Resolution', alpha * resolution / 2 + (1 - alpha) * resolution, step)\n",
        "    else:\n",
        "      writer.add_scalar('Resolution', resolution, step)\n",
        "\n",
        "    real = input_to_image(batch[:4]).astype(np.uint8)\n",
        "    if layer % 2 == 0:\n",
        "      g_out = generator.apply({'params': g_state.params}, latents)\n",
        "      gen = np.array(input_to_image(g_out).astype(np.uint8))\n",
        "      for (idx, img) in enumerate(gen):\n",
        "        Image.fromarray(img).save(f\"image{resolution}_{step}_{idx}.png\", \"PNG\")\n",
        "      writer.add_images(f\"images{resolution}/real\", real, step, dataformats='NHWC')\n",
        "      writer.add_images(f\"images{resolution}/generated\", gen, step, dataformats='NHWC')\n",
        "    else:\n",
        "      real_small = np.array(small_batch(real).astype(np.uint8))\n",
        "      (g_out_large, g_out_small) = generator.apply({'params': g_state.params}, latents)\n",
        "      (gen_large, gen_small) = (np.array(input_to_image(g_out_large).astype(np.uint8)), np.array(input_to_image(g_out_small).astype(np.uint8)))\n",
        "      for (idx, img) in enumerate(gen_large):\n",
        "        Image.fromarray(img).save(f\"image{resolution}_{step}_{idx}.png\", \"PNG\")\n",
        "      for (idx, img) in enumerate(gen_small):\n",
        "        Image.fromarray(img).save(f\"image{int(resolution/2)}_{step}_{idx}.png\", \"PNG\")\n",
        "      writer.add_images(f\"images{resolution}/real\", real, step, dataformats='NHWC')\n",
        "      writer.add_images(f\"images{int(resolution/2)}/real\", real_small, step, dataformats='NHWC')\n",
        "      writer.add_images(f\"images{resolution}/generated\", gen_large, step, dataformats='NHWC')\n",
        "      writer.add_images(f\"images{int(resolution/2)}/generated\", gen_small, step, dataformats='NHWC')\n",
        "    writer.add_scalar('Disk Usage (GiB)', shutil.disk_usage('.').used / (1024 * 1024 * 1024), step)\n",
        "\n",
        "    writer.flush()\n",
        "\n",
        "  if layer % 2 == 0:\n",
        "    d_state = disc_train_step(d_state, g_state, batch)\n",
        "    g_state = gen_train_step(d_state, g_state, batch)\n",
        "    (d_state, g_state) = compute_metrics(d_state, g_state, batch)\n",
        "  else:\n",
        "    batch_small = small_batch(batch)\n",
        "    d_state = disc_transition_train_step(d_state, g_state, batch, batch_small, alpha)\n",
        "    g_state = gen_transition_train_step(d_state, g_state, alpha, batch)\n",
        "    (d_state, g_state) = compute_metrics_transition(d_state, g_state, batch, batch_small, alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8qO19k178Yo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "6de5d3ff-9d32-4533-cafc-fbcced53f31e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-cf48807e510e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# stop execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert False # stop execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAACA_B-wbEm"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "for fil in sorted(glob.glob(\"*checkpoint*\"), key=lambda x: -int(x.split('_')[2].split('.')[0]))[:2]:\n",
        "  files.download(fil)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!tar -czf images_{run_id}.tar.gz image*png\n",
        "files.download(f\"images_{run_id}.tar.gz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NhzfSTopZpib",
        "outputId": "45879a94-4938-45fd-b29e-60c2ba58ad32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb9e7392-a1d0-45cd-862a-8a39984cae3d\", \"images_1693088093.tar.gz\", 43647582)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!tar -czf runs_{run_id}.tar.gz runs_{run_id}\n",
        "files.download(f\"runs_{run_id}.tar.gz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gxT-QsuKFkTs",
        "outputId": "972b573d-68b8-4c9a-9045-2dbc50863630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_117a0f3f-3929-4c5a-8fe4-230d0c50d716\", \"runs_1693088093.tar.gz\", 84281612)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIWuXkW-0VuP"
      },
      "outputs": [],
      "source": [
        "latents.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzNjsBs7JLOa"
      },
      "outputs": [],
      "source": [
        "!pip install -q ffmpegcv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7W6cA3yoc9E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a531505d-9fb6-4a14-b9e0-2d3a56726f7d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cdba69ba-8331-4300-891a-03b85ba3db8b\", \"output_1693088093.mp4\", 12322559)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b547ec8e-2e08-4acb-bceb-f2aaa5de9ddf\", \"generated_1693088093.png\", 262601)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import ffmpegcv\n",
        "\n",
        "# writer = ffmpegcv.VideoWriterNV(f\"output_{run_id}.mp4\", \"hevc\", 30, (512, 256))\n",
        "writer = cv2.VideoWriter(f\"output_{run_id}.mp4\", cv2.VideoWriter_fourcc('M','J','P','G'), 30, (1024, 384))\n",
        "\n",
        "images = glob.glob(\"image*png\")\n",
        "df = pd.DataFrame(images, columns=[\"filename\"])\n",
        "df[\"step\"] = df.filename.map(lambda x: int(x.split(\"_\")[1]))\n",
        "df[\"size\"] = df.filename.map(lambda x: int(x.split(\"_\")[0][len(\"image\"):]))\n",
        "df[\"idx\"] = df.filename.map(lambda x: int(x.split(\"_\")[2].split(\".\")[0]))\n",
        "\n",
        "sorted_grouped = df.sort_values([\"step\", \"size\", \"idx\"]).groupby(\"step\")\n",
        "\n",
        "def format_step(step):\n",
        "  if step < 1000:\n",
        "    return f\"{step}\"\n",
        "  elif step < 1000000:\n",
        "    return f\"{step/1000:.2f}K\"\n",
        "  else:\n",
        "    return f\"{step/1000000:.2f}M\"\n",
        "\n",
        "sstep = -1\n",
        "layer = None\n",
        "for step, group in sorted_grouped:\n",
        "  while sstep < step:\n",
        "    sstep += 1\n",
        "    if sstep in transitions:\n",
        "      layer = transitions.index(sstep)\n",
        "      resindex = int((layer+1)/2)\n",
        "      resolution = 4 * (2 ** resindex)\n",
        "\n",
        "  if layer % 2 == 1:\n",
        "    alpha = (transitions[layer+1] - step) / (transitions[layer+1] - transitions[layer])\n",
        "\n",
        "  footer1 = cv2.putText((255. * np.ones(shape=(64, 1024, 3))).astype(np.uint8), f\"Step {format_step(step)}\", org=(350, 44), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.5, color=(0, 0, 0))\n",
        "  if layer % 2 == 0:\n",
        "    imgs = np.array(jax.image.resize(jnp.array([cv2.imread(fil) for fil in group[group[\"size\"] == resolution][\"filename\"]] # 4 x resolution x resolution x 3\n",
        "                    ), shape=(4, 256, 256, 3), method=\"linear\")).transpose((1, 0, 2, 3)).reshape((256, 4*256, 3))\n",
        "    footer2 = cv2.putText((255. * np.ones(shape=(64, 1024, 3))).astype(np.uint8), f\"{resolution}x{resolution}\", org=(300, 36), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.5, color=(0, 0, 0))\n",
        "  else:\n",
        "    imgs_hi = np.array(jax.image.resize(jnp.array([cv2.imread(fil) for fil in group[group[\"size\"] == resolution][\"filename\"]] # 4 x resolution x resolution x 3\n",
        "                    ), shape=(4, 256, 256, 3), method=\"linear\")).transpose((1, 0, 2, 3)).reshape((256, 4*256, 3))\n",
        "    imgs_lo = np.array(jax.image.resize(jnp.array([cv2.imread(fil) for fil in group[group[\"size\"] == int(resolution/2)][\"filename\"]] # 4 x resolution/2 x resolution/2 x 3\n",
        "                    ), shape=(4, 256, 256, 3), method=\"linear\")).transpose((1, 0, 2, 3)).reshape((256, 4*256, 3))\n",
        "    imgs = ((1-alpha) * imgs_hi + alpha * imgs_lo).astype(np.uint8)\n",
        "    footer2 = cv2.putText((255. * np.ones(shape=(64, 1024, 3))).astype(np.uint8), f\"{resolution}x{resolution}: {1-alpha:.2f}  {int(resolution/2)}x{int(resolution/2)}: {alpha:.2f}  \", org=(300, 36), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.5, color=(0, 0, 0))\n",
        "  writer.write(np.concatenate([imgs, footer1, footer2]).astype(np.uint8))\n",
        "writer.release()\n",
        "files.download(f\"output_{run_id}.mp4\")\n",
        "cv2.imwrite(f\"generated_{run_id}.png\", imgs)\n",
        "files.download(f\"generated_{run_id}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBHe0ddyyojz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "98053db3-be58-45e1-d323-36d1138d5d7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_54b6a0c9-0cca-4287-b8eb-be7e3948e975\", \"latents.pickle\", 8420)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"latents.pickle\", \"wb\") as f:\n",
        "  pickle.dump(latents, f)\n",
        "\n",
        "files.download(\"latents.pickle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJzpK4NynfsS"
      },
      "outputs": [],
      "source": [
        "sampled_latents = sample_latent(256, jax.random.PRNGKey(0))\n",
        "(g_out128, g_out64, g_out32, g_out16, g_out8, g_out4) = generator.apply({'params': g_state.params, 'batch_stats': g_state.batch_stats}, sampled_latents, training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fSUg5RtE6ex"
      },
      "outputs": [],
      "source": [
        "def gridify(grid):\n",
        "  return np.transpose(grid.reshape((16, 16, 128, 128, 3)), axes=(0, 2, 1, 3, 4)).reshape(16*128, 16*128, 3)\n",
        "\n",
        "display.display(Image.fromarray(input_to_image(gridify(np.array(g_out128))).astype(np.uint8)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFu4_kv7Uu7O"
      },
      "outputs": [],
      "source": [
        "display.display(Image.fromarray(input_to_image(np.array(g_out128[15*16+4])).astype(np.uint8)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPX3Gdepm/7buovz1WpE7BT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}